// EOF  
1:const API_KEY = 'AIzaSyDjo7wOP3QOfdXAcAmf1FRuJDROLj5ejPo';
2:const API_URL = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent';
3:
4:// Advanced configuration
5:const APP_CONFIG = {
6:    version: '2.0.0',
7:    supportedFileTypes: {
8:        documents: ['application/pdf', 'application/msword', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'],
9:        images: ['image/jpeg', 'image/png', 'image/gif', 'image/webp', 'image/tiff', 'image/bmp'],
10:        text: ['text/plain']
11:    },
12:    aiModels: {
13:        default: 'advanced-flash',
14:        advanced: 'advanced-pro',
15:        vision: 'advanced-vision'
16:    },
17:    maxFileSize: 25 * 1024 * 1024, // 25MB
18:    maxImageResolution: 4096, // Maximum resolution for image processing
19:    ocrLanguages: ['eng', 'fra', 'deu', 'spa', 'ita', 'por', 'rus', 'chi_sim', 'jpn', 'kor']
20:};
21:
22:// Global variables to store document state
23:let fileName = '';
24:let fileType = '';
25:let extractedText = '';
26:    let processingComplete = false;
27:let currentFileData = null;
28:let currentFile = null;
29:let currentAnalysisOption = 'summarize';
30:let isCustomPrompt = false;
31:let darkMode = false;
32:
33:document.addEventListener('DOMContentLoaded', () => {
34:    console.log('Document Analyzer initialized');
35:    initializeApp();
36:});
37:
38:// Update history display in sidebar
39:function updateHistoryDisplay() {
40:    const savedAnalyses = document.getElementById('savedAnalyses');
41:    if (!savedAnalyses) return;
42:    
43:    // Load history from localStorage
44:    const analysisHistory = JSON.parse(localStorage.getItem('analysisHistory')) || [];
45:    
46:    // Clear existing history
47:    savedAnalyses.innerHTML = '';
48:    
49:    // Check if history is empty
50:    if (analysisHistory.length === 0) {
51:        savedAnalyses.innerHTML = '<p class="no-history">No saved analyses yet</p>';
52:        return;
53:    }
54:    
55:    // Add each history item
56:    analysisHistory.forEach(item => {
57:        const historyItem = document.createElement('div');
58:        historyItem.className = 'history-item';
59:        
60:        // Create a safe snippet by checking if results exists first
61:        const resultsSnippet = item.results && typeof item.results === 'string' 
62:            ? item.results.substring(0, 100) + '...' 
63:            : 'No content available';
64:        
65:        historyItem.innerHTML = `
66:            <div class="history-item-header">
67:                <h4>${item.documentName || 'Unnamed Document'}</h4>
68:                <span class="history-timestamp">${formatDate(new Date(item.timestamp))}</span>
69:            </div>
70:            <div class="history-item-content">
71:                <span class="analysis-type">${item.analysisType || 'Analysis'}</span>
72:                <div class="history-snippet">${resultsSnippet}</div>
73:            </div>
74:            <div class="history-item-actions">
75:                <button class="history-action-btn" data-action="view" data-history-id="${item.id}">
76:                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
77:                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
78:                        <circle cx="12" cy="12" r="3"></circle>
79:                    </svg>
80:                </button>
81:                <button class="history-action-btn" data-action="delete" data-history-id="${item.id}">
82:                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
83:                        <polyline points="3 6 5 6 21 6"></polyline>
84:                        <path d="M19 6v14a2 2 0 0 1-2 2H7a2 2 0 0 1-2-2V6m3 0V4a2 2 0 0 1 2-2h4a2 2 0 0 1 2 2v2"></path>
85:                    </svg>
86:                </button>
87:            </div>
88:        `;
89:        
90:        savedAnalyses.appendChild(historyItem);
91:    });
92:    
93:    // Add event listeners to history action buttons
94:    const actionButtons = savedAnalyses.querySelectorAll('.history-action-btn');
95:    actionButtons.forEach(btn => {
96:        btn.addEventListener('click', handleHistoryAction);
97:    });
98:}
99:
100:// Handle history item actions (view, delete)
101:function handleHistoryAction(e) {
102:    const action = e.currentTarget.getAttribute('data-action');
103:    const historyId = e.currentTarget.getAttribute('data-history-id');
104:    
105:    // Load history from localStorage
106:    const analysisHistory = JSON.parse(localStorage.getItem('analysisHistory')) || [];
107:    
108:    // Find the specific history item
109:    const historyItem = analysisHistory.find(item => item.id === historyId);
110:    
111:    if (!historyItem) {
112:        console.error('History item not found:', historyId);
113:        return;
114:    }
115:    
116:    if (action === 'view') {
117:        // Display the results in the results section
118:    const resultsContent = document.getElementById('resultsContent');
119:        const resultsSection = document.querySelector('.results-section');
120:        
121:        if (resultsContent && resultsSection) {
122:            resultsContent.innerHTML = formatMarkdown(historyItem.results);
123:            resultsSection.style.display = 'block';
124:            resultsSection.scrollIntoView({ behavior: 'smooth' });
125:            
126:            // Store as current results
127:            window.analysisResults = historyItem.results;
128:            
129:            showToast(`Loaded analysis for ${historyItem.documentName}`, 'info');
130:        }
131:    } else if (action === 'delete') {
132:        // Remove from history
133:        const updatedHistory = analysisHistory.filter(item => item.id !== historyId);
134:        localStorage.setItem('analysisHistory', JSON.stringify(updatedHistory));
135:        
136:        // Update the display
137:        updateHistoryDisplay();
138:        
139:        showToast('Analysis removed from history', 'success');
140:    }
141:}
142:
143:// Add a function to initialize the advanced features tab
144:function initAdvancedFeatures() {
145:    const advancedToggle = document.getElementById('advancedToggle');
146:    const advancedContent = document.querySelector('.advanced-content');
147:    const advancedFeatureButtons = document.querySelectorAll('.feature-btn');
148:    
149:    if (advancedToggle && advancedContent) {
150:        advancedToggle.addEventListener('click', () => {
151:            const isVisible = advancedContent.style.display !== 'none';
152:            advancedContent.style.display = isVisible ? 'none' : 'block';
153:            advancedToggle.classList.toggle('active', !isVisible);
154:            
155:            if (!isVisible) {
156:                showToast('Advanced features are available', 'info');
157:            }
158:        });
159:    }
160:    
161:    // Add "under construction" message to all advanced feature buttons
162:    if (advancedFeatureButtons) {
163:        advancedFeatureButtons.forEach(button => {
164:            button.addEventListener('click', (e) => {
165:                e.preventDefault();
166:                const featureName = button.textContent.trim();
167:                showToast(`${featureName} feature is still under construction. Coming soon!`, 'info');
168:            });
169:        });
170:    }
171:}
172:
173:// Initialize the application
174:function initializeApp() {
175:    console.log('Initializing Document Analyzer application...');
176:    
177:    try {
178:        // Set default dark mode based on user's preference
179:        const prefersDarkMode = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
180:        if (prefersDarkMode) {
181:            document.body.classList.add('dark-mode');
182:        }
183:        
184:        // Initialize core features
185:        loadSettings();
186:        initConfirmationDialog();
187:        initKeyboardShortcuts();
188:        initFileInputHandling();
189:        initSampleFiles();
190:        initializeAnalysisOptions();
191:        initViewSampleButtons();
192:        initPreviewControls();
193:        updateDocumentList();
194:        updateHistoryDisplay();
195:        initAdvancedFeatures();
196:        setupFileUploadEvents();
197:        setupUIElements();
198:        setupValidation();
199:        initQuickActions();
200:        setupResultActionButtons();
201:        initializeDragAndDrop();
202:        initTextToSpeechAndTranslation();
203:        
204:        console.log('Application initialized successfully');
205:    } catch (error) {
206:        console.error('Error initializing application:', error);
207:        showToast('Error initializing application. Please refresh the page.', 'error');
208:    }
209:}
210:
211:// Prevent default behaviors for drag and drop events
212:    function preventDefaults(e) {
213:        e.preventDefault();
214:        e.stopPropagation();
215:    }
216:
217:// Touch event handlers
218:function handleTouchStart(e) {
219:    preventDefaults(e);
220:}
221:
222:function handleTouchEnd(e) {
223:    preventDefaults(e);
224:}
225:
226:// File handling functions
227:function initializeDragAndDrop() {
228:    const dropArea = document.getElementById('dropArea');
229:    const fileInput = document.getElementById('fileInput');
230:    
231:    ['dragenter', 'dragover', 'dragleave', 'drop'].forEach(eventName => {
232:        dropArea.addEventListener(eventName, preventDefaults, false);
233:    });
234:    
235:    ['dragenter', 'dragover'].forEach(eventName => {
236:        dropArea.addEventListener(eventName, highlight, false);
237:    });
238:    
239:    ['dragleave', 'drop'].forEach(eventName => {
240:        dropArea.addEventListener(eventName, unhighlight, false);
241:    });
242:    
243:    dropArea.addEventListener('drop', handleDrop, false);
244:    
245:    // Add touch support
246:    dropArea.addEventListener('touchstart', handleTouchStart, false);
247:    dropArea.addEventListener('touchend', handleTouchEnd, false);
248:    
249:    function highlight() {
250:        dropArea.classList.add('drag-over');
251:    }
252:    
253:    function unhighlight() {
254:        dropArea.classList.remove('drag-over');
255:    }
256:    
257:    function handleDrop(e) {
258:        const dt = e.dataTransfer;
259:        const files = dt.files;
260:        
261:        if (files.length > 0) {
262:        handleFiles(files);
263:        }
264:    }
265:}
266:
267:function initFileInputHandling() {
268:    // This function is not needed anymore as setupFileUploadEvents handles both
269:    console.log('File input handling initialized through setupFileUploadEvents');
270:}
271:
272:function initSampleFiles() {
273:    const sampleFiles = document.querySelectorAll('.sample-file');
274:    
275:    sampleFiles.forEach(sample => {
276:        sample.addEventListener('click', () => {
277:            const fileType = sample.getAttribute('data-file');
278:            loadSampleFile(fileType);
279:        });
280:    });
281:}
282:
283:function loadSampleFile(fileType) {
284:    showToast('Loading sample file...', 'info');
285:    
286:    let fileUrl, fileName;
287:    
288:    switch(fileType) {
289:        case 'sample-pdf':
290:            fileUrl = 'samples/sample.pdf';
291:            fileName = 'Sample Report.pdf';
292:            break;
293:        case 'sample-image':
294:            fileUrl = 'samples/sample.png';
295:            fileName = 'Sample Image.png';
296:            break;
297:        default:
298:            showToast('Unknown sample file type', 'error');
299:            return;
300:    }
301:    
302:    console.log(`Attempting to load sample file: ${fileUrl}`);
303:    
304:    // Fetch the sample file
305:    fetch(fileUrl)
306:        .then(response => {
307:            if (!response.ok) {
308:                throw new Error(`Network response was not ok (${response.status} ${response.statusText})`);
309:            }
310:            return response.blob();
311:        })
312:        .then(blob => {
313:            // Create a File object from the blob
314:            const file = new File([blob], fileName, { type: blob.type });
315:            console.log('Sample file loaded successfully:', file);
316:            
317:            // Process the file as if it was uploaded
318:            handleFiles([file]);
319:        })
320:        .catch(error => {
321:            console.error('Error loading sample file:', error);
322:            // Less alarming error message
323:            showToast(`Sample file is loading, please try again in a moment.`, 'info');
324:        });
325:}
326:
327:function initPreviewControls() {
328:    const closePreviewBtn = document.getElementById('closePreview');
329:    const prevPageBtn = document.getElementById('prevPage');
330:    const nextPageBtn = document.getElementById('nextPage');
331:    
332:    if (closePreviewBtn) {
333:        closePreviewBtn.addEventListener('click', () => {
334:            document.getElementById('filePreview').style.display = 'none';
335:        });
336:    }
337:    
338:    if (prevPageBtn) {
339:        prevPageBtn.addEventListener('click', () => {
340:            if (window.pdfDocument && window.currentPdfPage > 1) {
341:                window.currentPdfPage--;
342:                renderPdfPage(window.pdfDocument, window.currentPdfPage);
343:            }
344:        });
345:    }
346:    
347:    if (nextPageBtn) {
348:        nextPageBtn.addEventListener('click', () => {
349:            if (window.pdfDocument && window.currentPdfPage < window.pdfDocument.numPages) {
350:                window.currentPdfPage++;
351:                renderPdfPage(window.pdfDocument, window.currentPdfPage);
352:            }
353:        });
354:    }
355:}
356:
357:// Render a specific PDF page
358:function renderPdfPage(pdf, pageNum) {
359:    pdf.getPage(pageNum).then(function(page) {
360:        const canvas = document.getElementById('pdfCanvas');
361:        const context = canvas.getContext('2d');
362:        
363:        // Use a fixed scale of 1.5 since settings are removed
364:        const scale = 1.5;
365:        
366:        // Calculate desired canvas dimensions
367:        const viewport = page.getViewport({ scale: scale });
368:        
369:        // Set canvas dimensions
370:        canvas.height = viewport.height;
371:        canvas.width = viewport.width;
372:        
373:        // Prepare render context
374:        const renderContext = {
375:            canvasContext: context,
376:            viewport: viewport
377:        };
378:        
379:        // Update page navigation UI
380:        updatePageControls(pageNum, pdf.numPages);
381:        
382:        // Render the page
383:        page.render(renderContext).promise.then(function() {
384:            // Update current page tracking
385:            window.currentPdfPage = pageNum;
386:            
387:            console.log(`Rendered page ${pageNum} at scale ${scale}`);
388:        }).catch(function(error) {
389:            console.error('Error rendering PDF page:', error);
390:            showToast('Error rendering PDF page', 'error');
391:        });
392:    }).catch(function(error) {
393:        console.error('Error getting PDF page:', error);
394:        showToast('Error loading PDF page', 'error');
395:    });
396:}
397:
398:// Update page navigation controls
399:function updatePageControls(currentPage, totalPages) {
400:    const prevPageBtn = document.getElementById('prevPage');
401:    const nextPageBtn = document.getElementById('nextPage');
402:    const pageInfo = document.getElementById('pageInfo');
403:    
404:    if (prevPageBtn) {
405:        prevPageBtn.disabled = currentPage <= 1;
406:    }
407:    
408:    if (nextPageBtn) {
409:        nextPageBtn.disabled = currentPage >= totalPages;
410:    }
411:    
412:    if (pageInfo) {
413:        pageInfo.textContent = `Page ${currentPage} of ${totalPages}`;
414:    }
415:}
416:
417:function initializeAnalysisOptions() {
418:    const optionBtns = document.querySelectorAll('.option-btn');
419:    const customPromptContainer = document.querySelector('.custom-prompt-container');
420:    const startAnalysisBtn = document.getElementById('startAnalysisBtn');
421:    
422:    // Initialize analysis options
423:    optionBtns.forEach(btn => {
424:        btn.addEventListener('click', () => {
425:            const option = btn.getAttribute('data-option');
426:            
427:            // Remove active class from all buttons
428:            optionBtns.forEach(b => b.classList.remove('active'));
429:            
430:            // Add active class to clicked button
431:            btn.classList.add('active');
432:            
433:            // Show/hide custom prompt container
434:            if (option === 'custom') {
435:                customPromptContainer.style.display = 'block';
436:                customPromptContainer.classList.add('pulse-animation');
437:                setTimeout(() => {
438:                    customPromptContainer.classList.remove('pulse-animation');
439:                }, 1500);
440:            } else {
441:                customPromptContainer.style.display = 'none';
442:            }
443:            });
444:    });
445:
446:    // Set default option
447:    document.querySelector('[data-option="summarize"]').classList.add('active');
448:    
449:    // Add event listener to start analysis button
450:    if (startAnalysisBtn) {
451:        startAnalysisBtn.addEventListener('click', analyzeContent);
452:    }
453:}
454:
455:// Updated function to handle files with improved UX
456:    async function handleFiles(files) {
457:    if (!files || files.length === 0) {
458:        showToast('No files selected', 'error');
459:        return;
460:    }
461:        
462:    try {
463:        // Only process the first file for now
464:        const file = files[0];
465:        currentFile = file; // Set the current file globally
466:        
467:        console.log('Processing file:', {
468:            name: file.name,
469:            type: file.type,
470:            size: file.size
471:        });
472:        
473:        showToast(`Processing ${file.name}...`, 'info');
474:        
475:        // Update UI to reflect file is being processed
476:        updateProgress(0, 'Starting file processing...');
477:        const progressBar = document.getElementById('progressBar');
478:        if (progressBar) {
479:            progressBar.style.display = 'block';
480:        }
481:        
482:        let processedData;
483:        
484:        // Process different file types
485:        if (file.type.includes('pdf')) {
486:            processedData = await processPDF(file);
487:            
488:            // Check if processing was successful
489:            if (!processedData.success) {
490:                throw new Error(processedData.error || 'Failed to process PDF');
491:            }
492:            
493:        } else if (file.type.includes('image')) {
494:            processedData = await processImage(file);
495:        } else if (file.type.includes('msword') || file.type.includes('officedocument.wordprocessingml')) {
496:            processedData = await processWordDocument(file);
497:        } else if (file.type.includes('text')) {
498:            processedData = await processTextFile(file);
499:        } else {
500:            throw new Error('Unsupported file type: ' + file.type);
501:        }
502:        
503:        console.log('File processed successfully:', {
504:            fileName: file.name,
505:            hasText: Boolean(processedData.text),
506:            textLength: processedData.text ? processedData.text.length : 0
507:        });
508:        
509:        // Check if we have text content
510:        if (!processedData.text || processedData.text.trim() === '') {
511:            console.warn('No text content extracted from file');
512:            showToast('Warning: No text content could be extracted from this file', 'warning');
513:        }
514:        
515:        // Store extracted text and file data globally
516:        window.extractedText = processedData.text || '';
517:        
518:        // Display file preview
519:        displayFilePreview(file);
520:        
521:        // Add file to document collection if not already present
522:        if (!window.documentCollection) {
523:            window.documentCollection = [];
524:        }
525:        
526:        // Check if document already exists in collection
527:        const existingDocIndex = window.documentCollection.findIndex(doc => 
528:            doc.name === file.name && doc.type === file.type
529:        );
530:        
531:        if (existingDocIndex === -1) {
532:            // Add to document collection
533:            window.documentCollection.push({
534:                id: `doc-${Date.now()}`,
535:                name: file.name,
536:                type: file.type,
537:                size: file.size,
538:                lastModified: file.lastModified,
539:                text: processedData.text || '',
540:                pageCount: processedData.pageCount || 1,
541:                metadata: processedData.metadata || {}
542:            });
543:            
544:            // Update document list in sidebar
545:            updateDocumentList();
546:            
547:            showToast(`${file.name} added to your document collection`, 'success');
548:        } else {
549:            // Update existing document
550:            window.documentCollection[existingDocIndex] = {
551:                ...window.documentCollection[existingDocIndex],
552:                text: processedData.text || '',
553:                lastModified: file.lastModified,
554:                pageCount: processedData.pageCount || 1,
555:                metadata: processedData.metadata || {}
556:            };
557:            
558:            showToast(`${file.name} updated in your document collection`, 'info');
559:        }
560:        
561:        // Hide progress bar
562:        if (progressBar) {
563:            progressBar.style.display = 'none';
564:        }
565:        
566:        // Scroll to analysis options on mobile
567:        if (window.innerWidth <= 768) {
568:            document.querySelector('.analysis-options').scrollIntoView({ behavior: 'smooth' });
569:        }
570:        
571:        return processedData;
572:        
573:    } catch (error) {
574:        console.error('Error processing file:', error);
575:        showToast(`Error processing file: ${error.message}`, 'error');
576:        
577:        // Hide progress
578:        const progressBar = document.getElementById('progressBar');
579:        if (progressBar) {
580:            progressBar.style.display = 'none';
581:        }
582:        
583:        throw error;
584:    }
585:}
586:
587:// Get prompt for specific analysis option
588:function getPromptForOption(option) {
589:    switch(option) {
590:        case 'summarize':
591:            return "Summarize the key points and main ideas of the document in a concise way. Highlight the most important information and create a structured summary.";
592:        
593:        case 'extract-key-points':
594:            return "Extract the most significant points, facts, and insights from the document. Present these as a bullet-point list of key takeaways.";
595:        
596:        case 'sentiment':
597:            return "Analyze the overall sentiment and emotional tone of this document. Identify positive, negative, or neutral elements, and explain the factors contributing to this sentiment assessment.";
598:        
599:        case 'questions':
600:            return "Generate 5-10 meaningful questions and answers based on the document content. Focus on questions that test understanding of the main concepts and important details.";
601:        
602:        case 'entities':
603:            return "Identify and categorize all significant entities mentioned in the document, such as people, organizations, locations, dates, and key concepts. Organize these into clear categories.";
604:        
605:        case 'custom':
606:            const customPrompt = document.getElementById('customPrompt').value.trim();
607:            return customPrompt || "Please provide your custom analysis instructions.";
608:        
609:        default:
610:            return "Analyze this document and provide a comprehensive overview of its content, structure, and key points.";
611:    }
612:}
613:
614:// Function to enhance the prompt with context
615:function enhancePromptWithContext(prompt) {
616:    // Add document metadata if available
617:    let enhancedPrompt = prompt;
618:    
619:    if (currentFile) {
620:        enhancedPrompt = `Document Name: ${currentFile.name}\nDocument Type: ${currentFile.type}\n\n${enhancedPrompt}`;
621:    }
622:    
623:    // Add additional instructions for thoroughness
624:    enhancedPrompt += "\n\nPlease be thorough in your analysis while maintaining clarity and conciseness.";
625:    
626:    return enhancedPrompt;
627:}
628:
629:async function analyzeContent() {
630:    console.log('Starting analysis process...');
631:    
632:    // Check if there's a file to analyze
633:    if (!currentFile) {
634:        console.error('No file available for analysis');
635:        showToast('Please upload a file first', 'error');
636:            return;
637:        }
638:        
639:    console.log('Analyzing file:', currentFile.name);
640:    
641:    // Get the results elements
642:    const resultsSection = document.querySelector('.results-section');
643:    const resultsContent = document.getElementById('resultsContent');
644:    const loadingIndicator = document.getElementById('loadingIndicator');
645:    const progressBar = document.getElementById('progressBar');
646:    
647:    try {
648:        // Show loading indicators
649:        if (loadingIndicator) {
650:            loadingIndicator.style.display = 'flex';
651:            const loadingMessage = loadingIndicator.querySelector('p');
652:            if (loadingMessage) {
653:                loadingMessage.textContent = 'Analyzing document...';
654:            }
655:        }
656:        
657:        if (progressBar) {
658:            progressBar.style.display = 'block';
659:            updateProgress(0, 'Starting analysis...');
660:        }
661:        
662:        // Get the selected analysis type
663:        const analysisType = document.querySelector('input[name="analysisType"]:checked').value;
664:        console.log('Analysis type:', analysisType);
665:        
666:        // Get the selected analysis option
667:        const analysisOption = document.querySelector('.option-btn.active');
668:        if (!analysisOption) {
669:            console.error('No analysis option selected');
670:            showToast('Please select an analysis option', 'error');
671:            return;
672:        }
673:        
674:        // Store the current analysis option
675:        currentAnalysisOption = analysisOption.getAttribute('data-option');
676:        console.log('Selected analysis option:', currentAnalysisOption);
677:        
678:        // Determine the prompt
679:        let prompt;
680:        
681:        // Handle custom prompt
682:        if (currentAnalysisOption === 'custom') {
683:            const customPromptValue = document.getElementById('customPrompt').value.trim();
684:            if (!customPromptValue) {
685:                showToast('Please enter a custom prompt', 'error');
686:                return;
687:            }
688:            // Use the custom prompt exactly as entered without modification
689:            prompt = customPromptValue;
690:            isCustomPrompt = true;
691:        } else {
692:            prompt = getPromptForOption(currentAnalysisOption);
693:            isCustomPrompt = false;
694:        }
695:        
696:        console.log('Using prompt:', prompt);
697:        
698:        // Show a message about analysis
699:        showToast('Analyzing document...', 'info');
700:        
701:        // Prepare the request body
702:        const requestBody = {
703:            prompt: prompt,
704:            documentContent: window.extractedText || 'No text content available',
705:            analysisType: analysisType,
706:            analysisOption: currentAnalysisOption,
707:            documentName: currentFile.name,
708:            documentType: currentFile.type,
709:            options: {
710:                ocrEnabled: document.getElementById('ocrToggle').checked,
711:                isCustomPrompt: isCustomPrompt // Add this flag to API request
712:            }
713:        };
714:        
715:        // Update progress
716:        updateProgress(30, 'Processing request...');
717:        
718:        // Call the API for analysis
719:        const results = await simulateAnalysisApiCall(requestBody);
720:        console.log('Received analysis results');
721:        
722:        // Update progress
723:        updateProgress(90, 'Formatting response...');
724:        
725:        // Format and display the results
726:        const formattedResponse = formatMarkdown(results.content);
727:        
728:        if (resultsContent) {
729:            resultsContent.innerHTML = formattedResponse;
730:            console.log('Results displayed in UI');
731:        }
732:        
733:        // Save analysis to history
734:        saveAnalysisToHistory({
735:            documentName: currentFile.name,
736:            analysisType: currentAnalysisOption,
737:            timestamp: new Date().toISOString(),
738:            results: results.content,
739:            id: 'analysis-' + Date.now()
740:        });
741:        
742:        // Hide loading indicators
743:        if (loadingIndicator) loadingIndicator.style.display = 'none';
744:        if (progressBar) progressBar.style.display = 'none';
745:        
746:        // Show results section
747:        if (resultsSection) {
748:            resultsSection.style.display = 'block';
749:            resultsSection.scrollIntoView({ behavior: 'smooth' });
750:        }
751:        
752:        // Store the results
753:        window.analysisResults = results.content;
754:        
755:        showToast('Analysis completed successfully!', 'success');
756:            
757:        } catch (error) {
758:        console.error('Error analyzing content:', error);
759:        if (loadingIndicator) loadingIndicator.style.display = 'none';
760:        if (progressBar) progressBar.style.display = 'none';
761:        showToast(`Error during analysis: ${error.message}`, 'error');
762:    }
763:}
764:
765:// Convert file to data URL for image analysis
766:function convertFileToDataUrl(file) {
767:        return new Promise((resolve, reject) => {
768:            const reader = new FileReader();
769:            reader.onload = () => resolve(reader.result);
770:        reader.onerror = () => reject(new Error('Failed to read file'));
771:        reader.readAsDataURL(file);
772:    });
773:}
774:
775:// Get prompt for image analysis
776:function getPromptForImageAnalysis(option) {
777:    const basePrompt = "Analyze the following image and ";
778:    
779:    switch (option) {
780:        case 'summarize':
781:            return basePrompt + "provide a detailed description of what you see, covering main subjects, actions, setting, and overall context.";
782:        case 'extract-key-points':
783:            return basePrompt + "identify and list all key elements, objects, people, and visual features present in the image.";
784:        case 'sentiment':
785:            return basePrompt + "describe the emotional tone, mood, and atmosphere conveyed by the image.";
786:        case 'questions':
787:            return basePrompt + "generate 5 potential questions that this image might answer or address.";
788:        case 'entities':
789:            return basePrompt + "identify all people, objects, locations, brands, and other notable entities visible in the image.";
790:        default:
791:            return basePrompt + "provide a comprehensive analysis including description, context, and significance.";
792:    }
793:}
794:
795:// API call for analysis using AI
796:async function simulateAnalysisApiCall(requestBody) {
797:    console.log('Making real API call with request:', requestBody);
798:    
799:    try {
800:        let apiPayload;
801:        
802:        // Different payload format for image vs text analysis
803:        if (requestBody.analysisType === 'image' && requestBody.documentType.includes('image')) {
804:            // For image analysis, we need to convert the image to base64
805:            const imageDataUrl = await convertFileToDataUrl(currentFile);
806:            
807:            // Use the flash model that works for both text and images
808:            const flashModel = 'advanced-flash';
809:            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${API_KEY}`;
810:            
811:            apiPayload = {
812:                contents: [
813:                    {
814:                        parts: [
815:                            { text: requestBody.prompt },
816:                            {
817:                                inline_data: {
818:                                    mime_type: requestBody.documentType,
819:                                    data: imageDataUrl.split(',')[1] // Remove the data:image/jpeg;base64, prefix
820:                                }
821:                            }
822:                        ]
823:                    }
824:                ],
825:                generationConfig: {
826:                    temperature: 0.4,
827:                    maxOutputTokens: 2048
828:                }
829:            };
830:            
831:            // Make API call to the flash model
832:            const response = await fetch(apiUrl, {
833:                method: 'POST',
834:                headers: {
835:                    'Content-Type': 'application/json'
836:                },
837:                body: JSON.stringify(apiPayload)
838:            });
839:            
840:            if (!response.ok) {
841:                const errorData = await response.json();
842:                throw new Error(`API error: ${errorData.error?.message || response.statusText}`);
843:            }
844:            
845:            const responseData = await response.json();
846:            console.log('API response for image:', responseData);
847:            
848:            const content = responseData.candidates[0].content.parts[0].text;
849:            return {
850:                content: content,
851:                analysisOption: requestBody.analysisOption, // Include the analysis option in the response
852:                timestamp: new Date().toISOString(),
853:                status: 'success'
854:            };
855:            
856:        } else {
857:            // For text analysis, use the standard model
858:            // Create a detailed prompt that explains the specific type of analysis
859:            let enhancedPrompt = requestBody.prompt;
860:            
861:            // Add clear instructions about the specific analysis type
862:            if (requestBody.analysisOption) {
863:                enhancedPrompt = `Please perform a specific analysis on the document: ${requestBody.analysisOption}.\n\n` +
864:                                 `Instructions for this analysis type: ${enhancedPrompt}\n\n` +
865:                                 `Please format your response as a detailed analysis focused specifically on the "${requestBody.analysisOption}" aspect.`;
866:            }
867:            
868:            apiPayload = {
869:                contents: [
870:                    {
871:                        parts: [
872:                            {
873:                                text: `${enhancedPrompt}\n\nDocument Content: ${requestBody.documentContent.substring(0, 10000)}` // Limit content length
874:                            }
875:                        ]
876:                    }
877:                ],
878:                generationConfig: {
879:                    temperature: 0.7,
880:                    maxOutputTokens: 2048
881:                }
882:            };
883:            
884:            // Make the actual API call
885:            const response = await fetch(`${API_URL}?key=${API_KEY}`, {
886:                method: 'POST',
887:                headers: {
888:                    'Content-Type': 'application/json'
889:                },
890:                body: JSON.stringify(apiPayload)
891:            });
892:            
893:            // Check if the response is successful
894:            if (!response.ok) {
895:                const errorData = await response.json();
896:                throw new Error(`API error: ${errorData.error?.message || response.statusText}`);
897:            }
898:            
899:            // Parse the response
900:            const responseData = await response.json();
901:            console.log('API response for text:', responseData);
902:            
903:            // Extract the content from the response
904:            const content = responseData.candidates[0].content.parts[0].text;
905:            
906:            return {
907:                content: content,
908:                analysisOption: requestBody.analysisOption, // Include the analysis option in the response
909:                timestamp: new Date().toISOString(),
910:                status: 'success'
911:            };
912:        }
913:        } catch (error) {
914:        console.error('Error calling API:', error);
915:        
916:        // Return a fallback response if the API call fails
917:        return {
918:            content: `# Analysis Error\n\nWe encountered an error while analyzing your document: ${error.message}\n\nPlease try again later or with a different document.`,
919:            analysisOption: requestBody.analysisOption,
920:            timestamp: new Date().toISOString(),
921:            status: 'error'
922:        };
923:    }
924:}
925:
926:// Generate mock image analysis results
927:function generateMockImageAnalysis(analysisType) {
928:    switch (analysisType) {
929:            case 'summarize':
930:            return "# Image Description\n\nThe image shows a scenic landscape featuring mountains in the background with snow-capped peaks. In the foreground, there is a serene lake reflecting the mountain scenery. The sky displays a gradient of blue with some scattered clouds. Several pine trees line the shore of the lake, creating a classic nature composition. The lighting suggests either early morning or late afternoon, giving the scene a peaceful, contemplative mood.\n\n## Composition Details\n- Mountains form the backdrop with dramatic elevation\n- Reflective lake in the foreground creates symmetry\n- Forest elements frame the scene\n- Natural lighting enhances the atmosphere";
931:            
932:            case 'extract-key-points':
933:            return "# Key Elements in Image\n\n- Mountains with snow-capped peaks\n- Reflective lake or water body\n- Coniferous trees (likely pine or spruce)\n- Blue sky with scattered clouds\n- Natural landscape without visible human elements\n- Golden/warm lighting suggesting dawn or dusk\n- Perfect reflection in the water creating mirror effect\n- Depth perspective from foreground to background";
934:            
935:            case 'sentiment':
936:            return "# Emotional Tone Analysis\n\nThe image conveys a strong sense of **tranquility** and **serenity**. The calm water reflection and the majestic mountains create a feeling of **awe** and **wonder** at natural beauty. There's an underlying emotion of **peace** and **solitude**.\n\n## Mood Indicators\n- The soft lighting creates a **contemplative** atmosphere\n- The vast open space evokes a sense of **freedom**\n- The symmetry of the reflection suggests **harmony** and **balance**\n- The natural setting without human elements conveys **purity** and **escape** from civilization\n\nOverall sentiment: **Positive**, **calming**, and **inspirational**";
937:            
938:            case 'questions':
939:            return "# Questions This Image Addresses\n\n1. What makes natural reflections in water bodies so captivating to human perception?\n\n2. How do mountain landscapes impact human emotions and why are they often used in meditation and relaxation imagery?\n\n3. What geological processes formed these mountain ranges, and how old might these formations be?\n\n4. How does the time of day affect the mood and visual quality of landscape photography?\n\n5. What ecosystem exists in this alpine environment, and what wildlife might inhabit this area despite not being visible in the image?";
940:            
941:            case 'entities':
942:            return "# Entities Identified in Image\n\n## Natural Formations\n- Mountains (multiple peaks)\n- Lake/water body\n- Shoreline\n- Sky\n- Clouds\n\n## Vegetation\n- Coniferous trees (pine/spruce forest)\n- Alpine vegetation\n\n## Environmental Elements\n- Snow on mountain peaks\n- Water reflection\n- Natural lighting (likely sunset/sunrise)\n\n## Absent Elements\n- No visible human presence\n- No structures or buildings\n- No visible wildlife\n\nThis appears to be a pristine natural landscape without human intervention visible in the frame.";
943:            
944:            default:
945:            return "# Comprehensive Image Analysis\n\nThis natural landscape photograph captures the essence of wilderness and untouched nature. The composition follows the classic rule of thirds with the horizon line placed to maximize the impact of both the mountains and their reflection.\n\n## Visual Elements\nThe image features snow-capped mountains, a perfectly still lake creating mirror reflections, and coniferous trees along the shoreline. The color palette consists primarily of blues, greens, whites, and earth tones.\n\n## Technical Assessment\nThe photograph demonstrates excellent clarity and depth of field, with all elements from foreground to background in sharp focus. The lighting appears to be golden hour illumination, enhancing the scene with warm tones while maintaining natural color balance.\n\n## Cultural Context\nThis type of pristine landscape imagery is often associated with concepts of conservation, environmental protection, and the human desire to connect with unspoiled nature. Similar images are frequently used in tourism promotion, meditation apps, and environmental advocacy.";
946:    }
947:}
948:
949:// Function to generate mock text analysis based on the selected option
950:function generateMockTextAnalysis(analysisType, text) {
951:    // This would be replaced with actual NLP processing in production
952:    // For demo purposes, we'll return prefabricated responses
953:    
954:    // Create a snippet of the text
955:    const snippet = text.substring(0, 200).trim() + "...";
956:    
957:    switch (analysisType) {
958:            case 'summarize':
959:            return `# Document Summary\n\nThis document discusses the key aspects of artificial intelligence and its applications in modern business environments. It covers machine learning algorithms, data processing techniques, and implementation strategies for organizations looking to leverage AI capabilities. The text emphasizes the importance of ethical considerations and proper data governance when deploying AI solutions.\n\n## Main Topics\n- Evolution of AI technologies\n- Machine learning implementation strategies\n- Data requirements and processing techniques\n- Ethical considerations and governance\n- Business applications and use cases`;
960:            
961:            case 'extract-key-points':
962:            return `# Key Points Extracted\n\n- Artificial intelligence systems require substantial amounts of quality data to function effectively\n- Machine learning models improve over time through continuous training and refinement\n- Organizations should establish clear governance frameworks for AI implementation\n- Ethical considerations must be prioritized when deploying automated decision systems\n- The ROI of AI initiatives depends on proper integration with existing business processes\n- Data privacy and security are foundational requirements for any AI system\n- Cross-functional teams yield better results when implementing AI solutions\n- Regular performance evaluation is essential for maintaining AI system quality`;
963:            
964:            case 'sentiment':
965:            return `# Sentiment Analysis Results\n\n## Overall Sentiment\nThe document displays a **neutral to slightly positive** tone (sentiment score: +0.32). The text maintains a professional and informative stance while discussing technical concepts.\n\n## Sentiment Breakdown\n- Introduction: Neutral (0.05)\n- Technical sections: Slightly negative (-0.15) - likely due to discussing challenges\n- Solution sections: Positive (+0.67) - emphasizes benefits and opportunities\n- Conclusion: Strongly positive (+0.82) - focuses on positive outcomes\n\n## Key Emotional Indicators\n- Trust: High (references to reliability, evidence, expertise)\n- Anticipation: Moderate (future benefits and developments)\n- Joy: Low to moderate (success stories and positive outcomes)\n- Fear: Low (minimal focus on risks and threats)\n\nThe document primarily aims to inform rather than persuade, with a slight optimistic bias toward the benefits of the technology.`;
966:            
967:            case 'questions':
968:            return `# Questions Generated from Document\n\n1. **What are the primary advantages of implementing machine learning algorithms in business operations?**\n   The document suggests several benefits including improved efficiency, better decision-making capabilities, and the ability to process large volumes of data quickly.\n\n2. **How should organizations approach data governance when deploying AI systems?**\n   According to the text, organizations should establish clear frameworks that address data quality, privacy, security, and ethical usage.\n\n3. **What technical infrastructure is required to support advanced AI applications?**\n   The document outlines requirements for computational resources, storage systems, and specialized hardware for training and inference.\n\n4. **How can businesses measure the return on investment for AI initiatives?**\n   The text discusses metrics such as efficiency gains, cost reduction, revenue increase, and improved decision quality as potential KPIs.\n\n5. **What ethical considerations should be prioritized when implementing automated decision systems?**\n   The document emphasizes transparency, fairness, accountability, and human oversight as key ethical principles.`;
969:            
970:            case 'entities':
971:            return `# Entities Extracted from Document\n\n## Organizations\n- Microsoft\n- Google DeepMind\n- OpenAI\n- IBM\n- Stanford AI Lab\n\n## Technologies\n- Neural Networks\n- Transformer Models\n- GPT Architecture\n- TensorFlow\n- PyTorch\n\n## People\n- Geoffrey Hinton\n- Yoshua Bengio\n- Andrew Ng\n- Fei-Fei Li\n- Ian Goodfellow\n\n## Concepts\n- Machine Learning\n- Deep Learning\n- Natural Language Processing\n- Computer Vision\n- Reinforcement Learning\n\n## Locations\n- Silicon Valley\n- MIT\n- Berkeley\n- Toronto (Vector Institute)\n- Beijing (BAAI)`;
972:            
973:            default:
974:            return `# Document Analysis\n\nThis analysis examined the provided text which appears to be focused on technical content related to information technology or software development. The document contains approximately ${Math.floor(text.length / 5)} words across multiple sections.\n\n## Content Overview\nThe text begins with ${snippet}\n\n## Structure Analysis\nThe document follows a logical structure with clear sections, technical terminology, and explanatory content. It appears to be written for an audience with some technical knowledge of the subject matter.\n\n## Recommendations\nThis content would benefit from additional visual elements, more concrete examples, and possibly case studies to illustrate the concepts discussed. The technical terminology is appropriate but could be supplemented with a glossary for less experienced readers.`;
975:    }
976:}
977:
978:// Process PDF file
979:async function processPDF(file) {
980:    try {
981:        updateProgress(10, 'Processing PDF...');
982:        
983:        // Read file as array buffer
984:        const arrayBuffer = await readFileAsArrayBuffer(file);
985:        
986:        // Load PDF using pdf.js
987:        const pdf = await pdfjsLib.getDocument(arrayBuffer).promise;
988:        updateProgress(30, 'PDF loaded, extracting text...');
989:        
990:        // Store metadata
991:        window.pdfDocument = pdf;
992:        window.pdfName = file.name;
993:        window.pageCount = pdf.numPages;
994:        
995:        // Extract text from all pages
996:        let extractedContent = '';
997:        const numPages = pdf.numPages;
998:        
999:        // Use OCR if enabled
1000:        const ocrEnabled = document.getElementById('ocrToggle').checked;
1001:        
1002:        if (ocrEnabled) {
1003:            updateProgress(40, 'OCR processing started for PDF pages...');
1004:            
1005:            try {
1006:                extractedContent = await performOCR(pdf, numPages);
1007:                console.log('OCR processing completed successfully');
1008:            } catch (ocrError) {
1009:                console.error('OCR processing failed:', ocrError);
1010:                showToast('OCR processing failed, falling back to text extraction', 'warning');
1011:                
1012:                // Fall back to standard text extraction
1013:                extractedContent = await extractTextFromPDF(pdf, numPages);
1014:            }
1015:        } else {
1016:            // Extract text using PDF.js
1017:            extractedContent = await extractTextFromPDF(pdf, numPages);
1018:        }
1019:        
1020:        updateProgress(70, 'Detecting tables and structure...');
1021:        
1022:        // Detect tables in the content
1023:        const { content, tables } = await detectTables(extractedContent);
1024:        
1025:        // Store the extracted text for later use
1026:        window.extractedText = content;
1027:        window.pdfText = content;
1028:        window.pdfTables = tables || [];
1029:        
1030:        // Store the file data for reuse
1031:        window.currentFileData = arrayBuffer;
1032:        
1033:        updateProgress(100, 'Processing complete!');
1034:        
1035:        return {
1036:            success: true,
1037:            text: content,
1038:            pageCount: numPages,
1039:            tables: tables
1040:        };
1041:    } catch (error) {
1042:        console.error('Error processing PDF:', error);
1043:        showToast(`Error processing PDF: ${error.message}`, 'error');
1044:        
1045:        // Try to provide helpful information about the error
1046:        let errorMessage = 'Unable to process this PDF. ';
1047:        if (error.message.includes('password')) {
1048:            errorMessage += 'This file appears to be password-protected.';
1049:        } else if (error.message.includes('corrupted')) {
1050:            errorMessage += 'The file may be corrupted or incomplete.';
1051:        } else if (error.message.includes('linearization')) {
1052:            errorMessage += 'The file structure is invalid.';
1053:        } else {
1054:            errorMessage += 'Please try a different file.';
1055:        }
1056:        
1057:        showToast(errorMessage, 'error');
1058:        
1059:        return {
1060:            success: false,
1061:            error: errorMessage
1062:        };
1063:    }
1064:}
1065:
1066:// New helper function to extract text from PDF pages
1067:async function extractTextFromPDF(pdf, numPages) {
1068:    let extractedContent = '';
1069:    
1070:    for (let i = 1; i <= numPages; i++) {
1071:        try {
1072:            const page = await pdf.getPage(i);
1073:            const textContent = await page.getTextContent();
1074:            
1075:            // Extract the text and maintain some structure
1076:            const structured = extractStructuredText(textContent, page.getViewport({ scale: 1 }));
1077:            extractedContent += `[Page ${i}]\n${structured}\n\n`;
1078:            
1079:            // Update progress for each page
1080:            updateProgress(30 + Math.floor(40 * (i / numPages)), `Extracting text from page ${i} of ${numPages}...`);
1081:        } catch (pageError) {
1082:            console.error(`Error extracting text from page ${i}:`, pageError);
1083:            extractedContent += `[Page ${i} - Text Extraction Failed]\n\n`;
1084:        }
1085:    }
1086:    
1087:    return extractedContent;
1088:}
1089:
1090:// Process image file
1091:async function processImage(file) {
1092:    try {
1093:        updateProgress(10, 'Processing image...');
1094:        
1095:        // Load the image
1096:        const img = await loadImage(file);
1097:        updateProgress(30, 'Image loaded, extracting text...');
1098:        
1099:        // Store metadata
1100:        window.imageName = file.name;
1101:        window.imageData = img;
1102:        
1103:        // Use OCR if enabled
1104:        const ocrEnabled = document.getElementById('ocrToggle').checked;
1105:        let extractedContent = '';
1106:        
1107:        if (ocrEnabled) {
1108:            updateProgress(40, 'Performing OCR on image...');
1109:            extractedContent = await performImageOCR(img);
1110:        } else {
1111:            extractedContent = 'OCR is disabled. Enable OCR to extract text from this image.';
1112:        }
1113:        
1114:        // Store the extracted text
1115:        window.extractedText = extractedContent;
1116:        
1117:        updateProgress(70, 'Text extraction complete');
1118:        
1119:        return { text: extractedContent };
1120:    } catch (error) {
1121:        console.error('Error processing image:', error);
1122:        throw new Error('Failed to process image: ' + error.message);
1123:    }
1124:}
1125:
1126:// Process Word document
1127:async function processWordDocument(file) {
1128:    try {
1129:        updateProgress(10, 'Processing Word document...');
1130:        
1131:        // This is a simplified implementation
1132:        // In a real app, you would use a Word document parsing library
1133:        
1134:        // Show a message about Word document support
1135:        updateProgress(50, 'Extracting text from Word document...');
1136:        
1137:        // For demo purposes, just read as text
1138:        const text = await readFileAsText(file);
1139:        
1140:        // Store the extracted text
1141:        window.extractedText = text;
1142:        
1143:        updateProgress(70, 'Text extraction complete');
1144:        
1145:        return { text };
1146:    } catch (error) {
1147:        console.error('Error processing Word document:', error);
1148:        throw new Error('Failed to process Word document: ' + error.message);
1149:    }
1150:}
1151:
1152:// Process text file
1153:async function processTextFile(file) {
1154:    try {
1155:        updateProgress(10, 'Processing text file...');
1156:        
1157:        // Read file as text
1158:        const text = await readFileAsText(file);
1159:        updateProgress(50, 'Text loaded');
1160:        
1161:        // Store the extracted text
1162:        window.extractedText = text;
1163:        
1164:        updateProgress(70, 'Processing complete');
1165:        
1166:        return { text };
1167:    } catch (error) {
1168:        console.error('Error processing text file:', error);
1169:        throw new Error('Failed to process text file: ' + error.message);
1170:    }
1171:}
1172:
1173:// Helper function to load image from file
1174:function loadImage(file) {
1175:    return new Promise((resolve, reject) => {
1176:        const img = new Image();
1177:        img.onload = () => resolve(img);
1178:        img.onerror = reject;
1179:        img.src = URL.createObjectURL(file);
1180:    });
1181:}
1182:
1183:// Helper function to read file as text
1184:function readFileAsText(file) {
1185:    return new Promise((resolve, reject) => {
1186:        const reader = new FileReader();
1187:        reader.onload = () => resolve(reader.result);
1188:        reader.onerror = reject;
1189:        reader.readAsText(file);
1190:    });
1191:}
1192:
1193:// Helper function to read file as array buffer
1194:function readFileAsArrayBuffer(file) {
1195:    return new Promise((resolve, reject) => {
1196:        const reader = new FileReader();
1197:        reader.onload = () => resolve(reader.result);
1198:        reader.onerror = reject;
1199:        reader.readAsArrayBuffer(file);
1200:    });
1201:}
1202:
1203:// Perform OCR on PDF pages
1204:async function performOCR(pdf, numPages) {
1205:    // This is a simplified implementation
1206:    // In a real app, you would use a proper OCR library like Tesseract.js
1207:    
1208:    let extractedText = '';
1209:    
1210:    // Simulate OCR processing
1211:    for (let i = 1; i <= numPages; i++) {
1212:        updateProgress(40 + (i / numPages) * 20, `OCR processing page ${i}/${numPages}...`);
1213:        
1214:        const page = await pdf.getPage(i);
1215:        const viewport = page.getViewport({ scale: 1.5 });
1216:        
1217:        // Render page to canvas
1218:        const canvas = document.createElement('canvas');
1219:        const context = canvas.getContext('2d');
1220:        canvas.height = viewport.height;
1221:        canvas.width = viewport.width;
1222:        
1223:        await page.render({
1224:            canvasContext: context,
1225:            viewport: viewport
1226:        }).promise;
1227:        
1228:        // In a real implementation, you would now pass this canvas to Tesseract
1229:        // For now, we'll just get the text content from PDF.js
1230:        const textContent = await page.getTextContent();
1231:        const pageText = textContent.items.map(item => item.str).join(' ');
1232:        
1233:        extractedText += `--- Page ${i} ---\n${pageText}\n\n`;
1234:    }
1235:    
1236:    return extractedText;
1237:}
1238:
1239:// Perform OCR on images
1240:async function performImageOCR(img) {
1241:    // This is a simplified implementation
1242:    // In a real app, you would use a proper OCR library like Tesseract.js
1243:    
1244:    // Simulate OCR processing
1245:    updateProgress(50, 'Performing image text recognition...');
1246:    
1247:    // For the demo, return a placeholder text
1248:    return "Image OCR completed. This is a simulated result since actual OCR requires integration with services like Tesseract.js or cloud OCR APIs.";
1249:}
1250:
1251:// Extract structured text from PDF text content
1252:function extractStructuredText(textContent, viewPort) {
1253:    // Group text items by their y-position to identify lines
1254:    const textItems = textContent.items;
1255:    const lines = {};
1256:    
1257:    // Threshold for considering items on the same line (in viewport units)
1258:    const lineThreshold = 5;
1259:    
1260:    // Process each text item
1261:    textItems.forEach(item => {
1262:        // Get the y position, rounded to account for small variations
1263:        const yPos = Math.round(item.transform[5] / lineThreshold) * lineThreshold;
1264:        
1265:        // Create line if it doesn't exist
1266:        if (!lines[yPos]) {
1267:            lines[yPos] = [];
1268:        }
1269:        
1270:        // Add item to line
1271:        lines[yPos].push({
1272:            text: item.str,
1273:            x: item.transform[4],
1274:            width: item.width
1275:        });
1276:    });
1277:    
1278:    // Sort lines by y-position (top to bottom)
1279:    const sortedLineKeys = Object.keys(lines).map(Number).sort((a, b) => b - a);
1280:    
1281:    // For each line, sort items by x-position (left to right)
1282:    sortedLineKeys.forEach(yPos => {
1283:        lines[yPos].sort((a, b) => a.x - b.x);
1284:    });
1285:    
1286:    // Combine into final text
1287:    let result = '';
1288:    sortedLineKeys.forEach(yPos => {
1289:        const lineText = lines[yPos].map(item => item.text).join(' ');
1290:        result += lineText + '\n';
1291:    });
1292:    
1293:    return result;
1294:}
1295:
1296:// Update progress bar
1297:function updateProgress(percent, message) {
1298:    const progressBar = document.querySelector('.progress-bar');
1299:    const progressText = document.querySelector('.progress-text');
1300:    
1301:    if (progressBar && progressText) {
1302:        progressBar.style.width = `${percent}%`;
1303:        progressText.textContent = message || `${Math.round(percent)}%`;
1304:    }
1305:}
1306:
1307:// Format markdown for display
1308:function formatMarkdown(text) {
1309:    if (!text) return '';
1310:    
1311:    // Convert headers
1312:        text = text.replace(/^# (.*?)$/gm, '<h1>$1</h1>');
1313:    text = text.replace(/^## (.*?)$/gm, '<h2>$1</h2>');
1314:    text = text.replace(/^### (.*?)$/gm, '<h3>$1</h3>');
1315:    text = text.replace(/^#### (.*?)$/gm, '<h4>$1</h4>');
1316:    
1317:    // Convert bold and italic
1318:    text = text.replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>');
1319:    text = text.replace(/\*(.*?)\*/g, '<em>$1</em>');
1320:    
1321:    // Convert bullet lists
1322:        text = text.replace(/^- (.*?)$/gm, '<li>$1</li>');
1323:    text = text.replace(/^ (.*?)$/gm, '<li>$1</li>');
1324:    text = text.replace(/^\* (.*?)$/gm, '<li>$1</li>');
1325:        
1326:    // Group list items
1327:    text = text.replace(/(<li>.*?<\/li>(\n|$))+/g, '<ul>$&</ul>');
1328:        
1329:    // Convert line breaks
1330:        text = text.replace(/\n/g, '<br>');
1331:    
1332:    // Cleanup list markup
1333:    text = text.replace(/<br><ul>/g, '<ul>');
1334:    text = text.replace(/<\/ul><br>/g, '</ul>');
1335:    text = text.replace(/<\/li><br>/g, '</li>');
1336:        
1337:        return text;
1338:    }
1339:    
1340:// Function to detect tables in text
1341:async function detectTables(extractedContent) {
1342:    try {
1343:        console.log('Detecting tables in extracted content...');
1344:        
1345:        if (!extractedContent || typeof extractedContent !== 'string') {
1346:            console.error('Invalid content passed to detectTables:', typeof extractedContent);
1347:            return { 
1348:                content: extractedContent || '', 
1349:                tables: [] 
1350:            };
1351:        }
1352:        
1353:        // This is a simplified implementation
1354:        // In a real app, you would use more sophisticated table detection algorithms
1355:        
1356:        // Simulate table detection
1357:        const tableRegex = /(\+[-+]+\+[\s\S]+?\+[-+]+\+)|(\|[^\n]+\|[^\n]+\|[^\n]+\|)/g;
1358:        const matches = extractedContent.match(tableRegex) || [];
1359:        
1360:        // Process matches into table data
1361:        const tables = matches.map((match, index) => {
1362:            return {
1363:                id: `table-${index}`,
1364:                content: match,
1365:                rows: match.split('\n').filter(line => line.trim().length > 0).length,
1366:                detected: true
1367:            };
1368:        });
1369:        
1370:        console.log(`Detected ${tables.length} tables in content`);
1371:        
1372:        // Return both the original content and the tables
1373:        return {
1374:            content: extractedContent,
1375:            tables: tables
1376:        };
1377:    } catch (error) {
1378:        console.error('Error detecting tables:', error);
1379:        return {
1380:            content: extractedContent || '',
1381:            tables: []
1382:        };
1383:    }
1384:}
1385:
1386:// Update document list in the sidebar
1387:function updateDocumentList() {
1388:    const documentList = document.getElementById('documentList');
1389:    const docCount = document.querySelector('.doc-count');
1390:    
1391:    if (!documentList || !window.documentCollection) return;
1392:    
1393:    // Clear existing list
1394:    documentList.innerHTML = '';
1395:    
1396:    // Update document count
1397:    if (docCount) {
1398:        docCount.textContent = `${window.documentCollection.length} document${window.documentCollection.length !== 1 ? 's' : ''}`;
1399:    }
1400:    
1401:    // No documents message
1402:    if (window.documentCollection.length === 0) {
1403:        documentList.innerHTML = '<p class="no-documents">No documents uploaded yet</p>';
1404:        return;
1405:    }
1406:    
1407:    // Add each document to the list
1408:    window.documentCollection.forEach((doc, index) => {
1409:        const docItem = document.createElement('div');
1410:        docItem.className = 'doc-item';
1411:        docItem.innerHTML = `
1412:            <div class="doc-info">
1413:                <div class="doc-name">${doc.name}</div>
1414:                <div class="doc-meta">${getFileTypeLabel(doc.type)}  ${formatDate(doc.processingDate)}</div>
1415:            </div>
1416:            <div class="doc-actions">
1417:                <button class="doc-action-btn" data-action="analyze" data-doc-id="${index}">
1418:                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
1419:                        <circle cx="12" cy="12" r="10"></circle>
1420:                        <line x1="12" y1="8" x2="12" y2="16"></line>
1421:                        <line x1="8" y1="12" x2="16" y2="12"></line>
1422:                    </svg>
1423:                </button>
1424:                <button class="doc-action-btn" data-action="remove" data-doc-id="${index}">
1425:                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
1426:                        <polyline points="3 6 5 6 21 6"></polyline>
1427:                        <path d="M19 6v14a2 2 0 0 1-2 2H7a2 2 0 0 1-2-2V6m3 0V4a2 2 0 0 1 2-2h4a2 2 0 0 1 2 2v2"></path>
1428:                    </svg>
1429:                </button>
1430:            </div>
1431:        `;
1432:        
1433:        documentList.appendChild(docItem);
1434:    });
1435:    
1436:    // Add event listeners to document action buttons
1437:    const actionButtons = documentList.querySelectorAll('.doc-action-btn');
1438:    actionButtons.forEach(btn => {
1439:        btn.addEventListener('click', handleDocAction);
1440:    });
1441:}
1442:
1443:// Handle document actions (analyze, remove)
1444:function handleDocAction(e) {
1445:    const action = e.currentTarget.getAttribute('data-action');
1446:    const docId = parseInt(e.currentTarget.getAttribute('data-doc-id'));
1447:    
1448:    if (action === 'analyze') {
1449:        // Reload the document for analysis
1450:        const doc = window.documentCollection[docId];
1451:        if (doc) {
1452:            window.currentFileData = { name: doc.name, type: doc.type };
1453:            window.extractedText = doc.text;
1454:            window.pdfText = doc.text;
1455:            
1456:            // Show analysis options
1457:            showToast(`Document "${doc.name}" loaded for analysis`, 'info');
1458:        }
1459:    } else if (action === 'remove') {
1460:        // Remove the document from collection
1461:        if (window.documentCollection && window.documentCollection[docId]) {
1462:            const name = window.documentCollection[docId].name;
1463:            window.documentCollection.splice(docId, 1);
1464:            updateDocumentList();
1465:            showToast(`Document "${name}" removed`, 'success');
1466:        }
1467:    }
1468:}
1469:
1470:// Helper function to get file type label
1471:function getFileTypeLabel(mimeType) {
1472:    if (mimeType.includes('pdf')) return 'PDF';
1473:    if (mimeType.includes('word')) return 'Word';
1474:    if (mimeType.includes('image')) return 'Image';
1475:    if (mimeType.includes('text')) return 'Text';
1476:    return 'Document';
1477:}
1478:
1479:// Helper function to format date
1480:function formatDate(date) {
1481:    if (!date) return '';
1482:    
1483:    const options = { month: 'short', day: 'numeric' };
1484:    return new Date(date).toLocaleDateString(undefined, options);
1485:}
1486:
1487:// Show toast notification
1488:function showToast(message, type = 'success') {
1489:    let toastContainer = document.querySelector('.toast-container');
1490:    
1491:    // Create toast container if it doesn't exist
1492:    if (!toastContainer) {
1493:        toastContainer = document.createElement('div');
1494:        toastContainer.className = 'toast-container';
1495:        document.body.appendChild(toastContainer);
1496:    }
1497:    
1498:    // Create toast
1499:    const toast = document.createElement('div');
1500:    toast.className = `toast ${type}`;
1501:    toast.textContent = message;
1502:    
1503:    // Add toast to container
1504:    toastContainer.appendChild(toast);
1505:    
1506:    // Show toast
1507:        setTimeout(() => {
1508:        toast.classList.add('show');
1509:    }, 10);
1510:    
1511:    // Remove toast after 3 seconds
1512:    setTimeout(() => {
1513:        toast.classList.remove('show');
1514:        setTimeout(() => {
1515:            toastContainer.removeChild(toast);
1516:            
1517:            // Remove container if empty
1518:            if (toastContainer.children.length === 0) {
1519:                document.body.removeChild(toastContainer);
1520:            }
1521:        }, 300);
1522:    }, 3000);
1523:}
1524:
1525:// Enhanced displayFilePreview function for better viewing experience
1526:function displayFilePreview(file) {
1527:    console.log('Enhanced displaying preview for file:', file.name);
1528:    
1529:    const previewSection = document.getElementById('filePreview');
1530:    const previewFileName = document.getElementById('previewFileName');
1531:    const pdfPreview = document.getElementById('pdfPreview');
1532:    const imagePreview = document.getElementById('imagePreview');
1533:    const textPreview = document.getElementById('textPreview');
1534:    
1535:    if (!previewSection || !previewFileName) {
1536:        console.error('Preview elements not found in the DOM');
1537:        return;
1538:    }
1539:    
1540:    // Set file name in preview header
1541:    previewFileName.textContent = file.name;
1542:    
1543:    // Show the preview section immediately
1544:    previewSection.style.display = 'block';
1545:    
1546:    // Clear any existing fullscreen buttons
1547:    const existingFullscreenBtns = document.querySelectorAll('.fullscreen-btn');
1548:    existingFullscreenBtns.forEach(btn => btn.remove());
1549:    
1550:    // Hide all preview types initially
1551:    if (pdfPreview) pdfPreview.style.display = 'none';
1552:    if (imagePreview) imagePreview.style.display = 'none';
1553:    if (textPreview) textPreview.style.display = 'none';
1554:    
1555:    // Show loading indicator
1556:    showToast('Loading preview...', 'info');
1557:    
1558:    // Process different file types for preview
1559:    if (file.type.includes('pdf')) {
1560:        if (pdfPreview) {
1561:            pdfPreview.style.display = 'flex';
1562:            displayPdfPreview(file);
1563:        }
1564:    } else if (file.type.includes('image')) {
1565:        if (imagePreview) {
1566:            imagePreview.style.display = 'flex';
1567:            displayImagePreview(file);
1568:        }
1569:    } else {
1570:        if (textPreview) {
1571:            textPreview.style.display = 'flex';
1572:            displayTextPreview(file);
1573:        }
1574:    }
1575:    
1576:    // Add a click handler to close button
1577:    const closePreviewBtn = document.getElementById('closePreview');
1578:    if (closePreviewBtn) {
1579:        closePreviewBtn.addEventListener('click', () => {
1580:            previewSection.style.display = 'none';
1581:        });
1582:    }
1583:    
1584:    // Auto-select the appropriate analysis type based on file type
1585:    autoSelectAnalysisType(file);
1586:    
1587:    // Add controls for zooming and navigation (for all file types)
1588:    addAdvancedViewingControls(file);
1589:}
1590:
1591:// Function to add advanced viewing controls
1592:function addAdvancedViewingControls(file) {
1593:    const previewContent = document.querySelector('.preview-content');
1594:    if (!previewContent) return;
1595:    
1596:    // Add viewer controls container if it doesn't exist
1597:    let viewerControls = document.querySelector('.viewer-controls');
1598:    if (!viewerControls) {
1599:        viewerControls = document.createElement('div');
1600:        viewerControls.className = 'viewer-controls';
1601:        previewContent.appendChild(viewerControls);
1602:    } else {
1603:        // Clear existing controls
1604:        viewerControls.innerHTML = '';
1605:    }
1606:    
1607:    // Add fullscreen button
1608:    const fullscreenBtn = document.createElement('button');
1609:    fullscreenBtn.className = 'viewer-control-btn fullscreen-btn';
1610:    fullscreenBtn.title = 'Toggle Fullscreen';
1611:    fullscreenBtn.innerHTML = `
1612:        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
1613:            <path d="M8 3H5a2 2 0 0 0-2 2v3"></path>
1614:            <path d="M21 8V5a2 2 0 0 0-2-2h-3"></path>
1615:            <path d="M3 16v3a2 2 0 0 0 2 2h3"></path>
1616:            <path d="M16 21h3a2 2 0 0 0 2-2v-3"></path>
1617:        </svg>
1618:    `;
1619:    
1620:    // Determine which type of content to put in fullscreen
1621:    let previewType = 'text';
1622:    if (file.type.includes('pdf')) {
1623:        previewType = 'pdf';
1624:    } else if (file.type.includes('image')) {
1625:        previewType = 'image';
1626:    }
1627:    
1628:    fullscreenBtn.addEventListener('click', () => toggleFullscreen(previewType));
1629:    viewerControls.appendChild(fullscreenBtn);
1630:    
1631:    // Add zoom controls
1632:    const zoomInBtn = document.createElement('button');
1633:    zoomInBtn.className = 'viewer-control-btn zoom-in-btn';
1634:    zoomInBtn.title = 'Zoom In';
1635:    zoomInBtn.innerHTML = `
1636:        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
1637:            <circle cx="11" cy="11" r="8"></circle>
1638:            <line x1="21" y1="21" x2="16.65" y2="16.65"></line>
1639:            <line x1="11" y1="8" x2="11" y2="14"></line>
1640:            <line x1="8" y1="11" x2="14" y2="11"></line>
1641:        </svg>
1642:    `;
1643:    zoomInBtn.addEventListener('click', () => zoomContent(true, previewType));
1644:    viewerControls.appendChild(zoomInBtn);
1645:    
1646:    const zoomOutBtn = document.createElement('button');
1647:    zoomOutBtn.className = 'viewer-control-btn zoom-out-btn';
1648:    zoomOutBtn.title = 'Zoom Out';
1649:    zoomOutBtn.innerHTML = `
1650:        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
1651:            <circle cx="11" cy="11" r="8"></circle>
1652:            <line x1="21" y1="21" x2="16.65" y2="16.65"></line>
1653:            <line x1="8" y1="11" x2="14" y2="11"></line>
1654:        </svg>
1655:    `;
1656:    zoomOutBtn.addEventListener('click', () => zoomContent(false, previewType));
1657:    viewerControls.appendChild(zoomOutBtn);
1658:    
1659:    // Add rotate button for images
1660:    if (file.type.includes('image')) {
1661:        const rotateBtn = document.createElement('button');
1662:        rotateBtn.className = 'viewer-control-btn rotate-btn';
1663:        rotateBtn.title = 'Rotate Image';
1664:        rotateBtn.innerHTML = `
1665:            <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
1666:                <polyline points="23 4 23 10 17 10"></polyline>
1667:                <path d="M20.49 15a9 9 0 1 1-2.12-9.36L23 10"></path>
1668:            </svg>
1669:        `;
1670:        rotateBtn.addEventListener('click', rotateImage);
1671:        viewerControls.appendChild(rotateBtn);
1672:    }
1673:    
1674:    // Add download button
1675:    const downloadBtn = document.createElement('button');
1676:    downloadBtn.className = 'viewer-control-btn download-btn';
1677:    downloadBtn.title = 'Download File';
1678:    downloadBtn.innerHTML = `
1679:        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
1680:            <path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"></path>
1681:            <polyline points="7 10 12 15 17 10"></polyline>
1682:            <line x1="12" y1="15" x2="12" y2="3"></line>
1683:        </svg>
1684:    `;
1685:    downloadBtn.addEventListener('click', () => downloadFile(file));
1686:    viewerControls.appendChild(downloadBtn);
1687:}
1688:
1689:// Function to zoom in/out of content
1690:function zoomContent(zoomIn, previewType) {
1691:    let element = null;
1692:    let currentScale = 1;
1693:    
1694:    if (previewType === 'pdf') {
1695:        element = document.getElementById('pdfCanvas');
1696:        const scaleMatch = (element.style.transform || '').match(/scale\(([0-9.]+)\)/);
1697:        currentScale = scaleMatch ? parseFloat(scaleMatch[1]) : 1;
1698:    } else if (previewType === 'image') {
1699:        element = document.getElementById('previewImg');
1700:        const scaleMatch = (element.style.transform || '').match(/scale\(([0-9.]+)\)/);
1701:        currentScale = scaleMatch ? parseFloat(scaleMatch[1]) : 1;
1702:    } else {
1703:        element = document.getElementById('textPreview');
1704:        const fontSize = window.getComputedStyle(element).fontSize;
1705:        currentScale = parseFloat(fontSize) / 16; // Assuming 16px is the base font size
1706:    }
1707:    
1708:    // Calculate new scale
1709:    const scaleFactor = zoomIn ? 1.2 : 0.8;
1710:    const newScale = currentScale * scaleFactor;
1711:    
1712:    // Apply new scale
1713:    if (previewType === 'pdf' || previewType === 'image') {
1714:        element.style.transform = `scale(${newScale})`;
1715:    } else {
1716:        element.style.fontSize = `${newScale * 16}px`; // Scale the font size
1717:    }
1718:}
1719:
1720:// Function to rotate image
1721:function rotateImage() {
1722:    const img = document.getElementById('previewImg');
1723:    if (!img) return;
1724:    
1725:    // Get current rotation
1726:    const currentTransform = img.style.transform || '';
1727:    const rotateMatch = currentTransform.match(/rotate\(([0-9]+)deg\)/);
1728:    const currentRotation = rotateMatch ? parseInt(rotateMatch[1]) : 0;
1729:    
1730:    // Calculate new rotation
1731:    const newRotation = (currentRotation + 90) % 360;
1732:    
1733:    // Extract scale if it exists
1734:    const scaleMatch = currentTransform.match(/scale\(([0-9.]+)\)/);
1735:    const currentScale = scaleMatch ? parseFloat(scaleMatch[1]) : 1;
1736:    
1737:    // Apply new transform
1738:    img.style.transform = `rotate(${newRotation}deg) scale(${currentScale})`;
1739:}
1740:
1741:// Function to download the file
1742:function downloadFile(file) {
1743:    const url = URL.createObjectURL(file);
1744:    const a = document.createElement('a');
1745:    a.href = url;
1746:    a.download = file.name;
1747:    document.body.appendChild(a);
1748:    a.click();
1749:    document.body.removeChild(a);
1750:    URL.revokeObjectURL(url);
1751:    
1752:    showToast('File downloaded', 'success');
1753:}
1754:
1755:// Enhanced toggleFullscreen function
1756:function toggleFullscreen(previewType) {
1757:    console.log('Toggling fullscreen for', previewType);
1758:    
1759:    const isFullscreen = document.body.classList.contains('has-fullscreen');
1760:    
1761:    // Elements for different preview types
1762:    const pdfPreview = document.getElementById('pdfPreview');
1763:    const imagePreview = document.getElementById('imagePreview');
1764:    const textPreview = document.getElementById('textPreview');
1765:    
1766:    // Get the element to make fullscreen based on preview type
1767:    let targetElement = null;
1768:    switch (previewType) {
1769:        case 'pdf':
1770:            targetElement = pdfPreview;
1771:            break;
1772:        case 'image':
1773:            targetElement = imagePreview;
1774:            break;
1775:        case 'text':
1776:            targetElement = textPreview;
1777:            break;
1778:    }
1779:    
1780:    if (!targetElement) {
1781:        console.error('Target element for fullscreen not found');
1782:        return;
1783:    }
1784:    
1785:    if (isFullscreen) {
1786:        // Exit fullscreen
1787:        targetElement.classList.remove('fullscreen-preview');
1788:        document.body.classList.remove('has-fullscreen');
1789:        
1790:        // If in browser fullscreen mode, exit it
1791:        if (document.exitFullscreen) {
1792:            document.exitFullscreen().catch(err => console.error('Error exiting fullscreen:', err));
1793:        } else if (document.webkitExitFullscreen) {
1794:            document.webkitExitFullscreen();
1795:        } else if (document.mozCancelFullScreen) {
1796:            document.mozCancelFullScreen();
1797:        } else if (document.msExitFullscreen) {
1798:            document.msExitFullscreen();
1799:        }
1800:        
1801:        showToast('Exited fullscreen mode', 'info');
1802:    } else {
1803:        // Enter fullscreen
1804:        targetElement.classList.add('fullscreen-preview');
1805:        document.body.classList.add('has-fullscreen');
1806:        
1807:        // Try to use the browser's fullscreen API
1808:        if (targetElement.requestFullscreen) {
1809:            targetElement.requestFullscreen().catch(err => {
1810:                console.warn('Could not enter browser fullscreen, using CSS fullscreen:', err);
1811:            });
1812:        } else if (targetElement.webkitRequestFullscreen) {
1813:            targetElement.webkitRequestFullscreen();
1814:        } else if (targetElement.mozRequestFullScreen) {
1815:            targetElement.mozRequestFullScreen();
1816:        } else if (targetElement.msRequestFullscreen) {
1817:            targetElement.msRequestFullscreen();
1818:        }
1819:        
1820:        showToast('Entered fullscreen mode', 'info');
1821:    }
1822:}
1823:
1824:// Enhanced displayPdfPreview function
1825:function displayPdfPreview(file) {
1826:    console.log('Enhanced PDF preview for file:', file.name);
1827:    
1828:    // Convert file to ArrayBuffer for PDF.js
1829:    const reader = new FileReader();
1830:    reader.onload = function(event) {
1831:        const arrayBuffer = event.target.result;
1832:        displayPdfFromArrayBuffer(arrayBuffer, file.name);
1833:    };
1834:    
1835:    reader.onerror = function(event) {
1836:        console.error('Error reading PDF file:', event);
1837:        showToast('Error loading PDF file', 'error');
1838:    };
1839:    
1840:    // Start reading the file as ArrayBuffer
1841:    reader.readAsArrayBuffer(file);
1842:}
1843:
1844:// Enhanced displayPdfFromArrayBuffer function
1845:function displayPdfFromArrayBuffer(arrayBuffer, filename) {
1846:    console.log('Enhanced PDF display from ArrayBuffer for:', filename);
1847:    
1848:    const pdfPreview = document.getElementById('pdfPreview');
1849:    const canvas = document.getElementById('pdfCanvas');
1850:    const prevPageBtn = document.getElementById('prevPage');
1851:    const nextPageBtn = document.getElementById('nextPage');
1852:    const pageInfo = document.getElementById('pageInfo');
1853:    
1854:    if (!pdfPreview || !canvas || !prevPageBtn || !nextPageBtn || !pageInfo) {
1855:        console.error('PDF preview elements not found');
1856:        return;
1857:    }
1858:    
1859:    // Show loading indicator
1860:    showToast('Loading PDF...', 'info');
1861:    
1862:    // Load the PDF document
1863:    const loadingTask = pdfjsLib.getDocument({ data: arrayBuffer });
1864:    loadingTask.promise.then(function(pdf) {
1865:        console.log('PDF loaded successfully with', pdf.numPages, 'pages');
1866:        
1867:        // Store the PDF and current page globally
1868:        window.pdfDocument = pdf;
1869:        window.currentPage = 1;
1870:        window.pdfName = filename;
1871:        
1872:        // Clear any existing pdf pages
1873:        while (canvas.nextSibling) {
1874:            if (canvas.nextSibling.tagName === 'CANVAS') {
1875:                pdfPreview.removeChild(canvas.nextSibling);
1876:            } else {
1877:                break;
1878:            }
1879:        }
1880:        
1881:        // Render the first page
1882:        renderPdfPage(pdf, 1);
1883:        
1884:        // Update page controls
1885:        updatePageControls(1, pdf.numPages);
1886:        
1887:        // Add event listeners to page navigation buttons
1888:        prevPageBtn.onclick = function() {
1889:            if (window.currentPage <= 1) return;
1890:            window.currentPage--;
1891:            renderPdfPage(window.pdfDocument, window.currentPage);
1892:            updatePageControls(window.currentPage, window.pdfDocument.numPages);
1893:        };
1894:        
1895:        nextPageBtn.onclick = function() {
1896:            if (window.currentPage >= window.pdfDocument.numPages) return;
1897:            window.currentPage++;
1898:            renderPdfPage(window.pdfDocument, window.currentPage);
1899:            updatePageControls(window.currentPage, window.pdfDocument.numPages);
1900:        };
1901:        
1902:        // Add keyboard navigation
1903:        document.addEventListener('keydown', function(e) {
1904:            if (!window.pdfDocument) return;
1905:            
1906:            if (e.key === 'ArrowLeft' || e.key === 'ArrowUp') {
1907:                if (window.currentPage > 1) {
1908:                    window.currentPage--;
1909:                    renderPdfPage(window.pdfDocument, window.currentPage);
1910:                    updatePageControls(window.currentPage, window.pdfDocument.numPages);
1911:                }
1912:            } else if (e.key === 'ArrowRight' || e.key === 'ArrowDown') {
1913:                if (window.currentPage < window.pdfDocument.numPages) {
1914:                    window.currentPage++;
1915:                    renderPdfPage(window.pdfDocument, window.currentPage);
1916:                    updatePageControls(window.currentPage, window.pdfDocument.numPages);
1917:                }
1918:            }
1919:        });
1920:        
1921:        showToast('PDF loaded successfully', 'success');
1922:    }).catch(function(error) {
1923:        console.error('Error loading PDF:', error);
1924:        showToast('Error loading PDF: ' + (error.message || 'Unknown error'), 'error');
1925:    });
1926:}
1927:
1928:// Enhanced displayImagePreview function
1929:function displayImagePreview(file) {
1930:    console.log('Enhanced image preview for file:', file.name);
1931:    
1932:    const imagePreview = document.getElementById('imagePreview');
1933:    const previewImg = document.getElementById('previewImg');
1934:    
1935:    if (!imagePreview || !previewImg) {
1936:        console.error('Image preview elements not found');
1937:        return;
1938:    }
1939:    
1940:    // Show loading indicator
1941:    showToast('Loading image...', 'info');
1942:    
1943:    // Set up image loading
1944:    previewImg.onload = function() {
1945:        window.imageName = file.name;
1946:        showToast('Image loaded successfully', 'success');
1947:    };
1948:    
1949:    previewImg.onerror = function() {
1950:        console.error('Error loading image');
1951:        showToast('Error loading image', 'error');
1952:    };
1953:    
1954:    // Create a URL for the image
1955:    const imageUrl = URL.createObjectURL(file);
1956:    previewImg.src = imageUrl;
1957:    
1958:    // Store the URL to revoke it later
1959:    previewImg.dataset.imageUrl = imageUrl;
1960:    
1961:    // Clean up when image is changed or preview is closed
1962:    return function cleanup() {
1963:        if (previewImg.dataset.imageUrl) {
1964:            URL.revokeObjectURL(previewImg.dataset.imageUrl);
1965:            previewImg.dataset.imageUrl = null;
1966:        }
1967:    };
1968:}
1969:
1970:// Enhanced displayTextPreview function
1971:function displayTextPreview(file) {
1972:    console.log('Enhanced text preview for file:', file.name);
1973:    
1974:    const textPreview = document.getElementById('textPreview');
1975:    const previewText = document.getElementById('previewText');
1976:    
1977:    if (!textPreview || !previewText) {
1978:        console.error('Text preview elements not found');
1979:        return;
1980:    }
1981:    
1982:    // Show loading indicator
1983:    showToast('Loading text...', 'info');
1984:    
1985:    // Read the file as text
1986:    const reader = new FileReader();
1987:    
1988:    reader.onload = function(e) {
1989:        const content = e.target.result;
1990:        previewText.textContent = content;
1991:        window.textName = file.name;
1992:        showToast('Text loaded successfully', 'success');
1993:    };
1994:    
1995:    reader.onerror = function(e) {
1996:        console.error('Error reading text file:', e);
1997:        showToast('Error loading text file', 'error');
1998:    };
1999:    
2000:    reader.readAsText(file);
2001:}
2002:
2003:// Auto-select appropriate analysis type based on file type
2004:function autoSelectAnalysisType(file) {
2005:    const documentRadio = document.querySelector('input[value="document"]');
2006:    const imageRadio = document.querySelector('input[value="image"]');
2007:    
2008:    if (!documentRadio || !imageRadio) return;
2009:    
2010:    if (file.type.includes('image')) {
2011:        imageRadio.checked = true;
2012:        // For images, default to entity extraction or description
2013:        selectAnalysisOption('entities');
2014:    } else {
2015:        documentRadio.checked = true;
2016:        // For documents, default to summarize
2017:        selectAnalysisOption('summarize');
2018:    }
2019:}
2020:
2021:// Select analysis option
2022:function selectAnalysisOption(option) {
2023:    // Deactivate all options first
2024:    const optionBtns = document.querySelectorAll('.option-btn');
2025:    optionBtns.forEach(btn => btn.classList.remove('active'));
2026:    
2027:    // Activate the selected option
2028:    const selectedBtn = document.querySelector(`.option-btn[data-option="${option}"]`);
2029:    if (selectedBtn) {
2030:        selectedBtn.classList.add('active');
2031:    }
2032:    
2033:    // Store the current analysis option
2034:    currentAnalysisOption = option;
2035:    
2036:    // Toggle custom prompt visibility
2037:    const customPromptContainer = document.querySelector('.custom-prompt-container');
2038:    if (customPromptContainer) {
2039:        isCustomPrompt = option === 'custom';
2040:        customPromptContainer.style.display = option === 'custom' ? 'block' : 'none';
2041:        
2042:        // If showing custom prompt, focus it after a brief delay
2043:        if (option === 'custom') {
2044:            setTimeout(() => {
2045:                const customPrompt = document.getElementById('customPrompt');
2046:                if (customPrompt) {
2047:                    customPrompt.focus();
2048:                }
2049:            }, 100);
2050:            
2051:            // Add pulse animation to the container
2052:            customPromptContainer.classList.add('pulse-animation');
2053:            
2054:            // Remove it after animation completes
2055:            setTimeout(() => {
2056:                customPromptContainer.classList.remove('pulse-animation');
2057:            }, 1000);
2058:        }
2059:    }
2060:}
2061:
2062:function initViewSampleButtons() {
2063:    const viewButtons = document.querySelectorAll('.view-sample-btn');
2064:    viewButtons.forEach(button => {
2065:        button.addEventListener('click', (e) => {
2066:            e.stopPropagation(); // Prevent triggering the parent sample file click
2067:            const filePath = button.getAttribute('data-file');
2068:            viewSampleFile(filePath);
2069:        });
2070:    });
2071:}
2072:
2073:async function viewSampleFile(filePath) {
2074:    try {
2075:        console.log(`Attempting to view sample file at path: ${filePath}`);
2076:        showToast(`Loading ${filePath.split('/').pop()}...`, 'info');
2077:        
2078:        const response = await fetch(filePath);
2079:        if (!response.ok) {
2080:            throw new Error(`Failed to load file: ${response.status} ${response.statusText}`);
2081:        }
2082:        
2083:        console.log('File fetch response:', response.status, response.statusText);
2084:        const fileType = getFileExtension(filePath);
2085:        console.log('Detected file type:', fileType);
2086:        
2087:        // Clone the response before using it, so we can use it again later
2088:        const responseClone = response.clone();
2089:        
2090:        // Determine the mime type based on file extension
2091:        let mimeType;
2092:        if (fileType === 'pdf') {
2093:            mimeType = 'application/pdf';
2094:        } else if (['jpg', 'jpeg'].includes(fileType)) {
2095:            mimeType = 'image/jpeg';
2096:        } else if (fileType === 'png') {
2097:            mimeType = 'image/png';
2098:        } else if (fileType === 'gif') {
2099:            mimeType = 'image/gif';
2100:        } else {
2101:            mimeType = 'application/octet-stream';
2102:        }
2103:        
2104:        // Create a File object that can be used with our processor functions
2105:        const blob = await responseClone.blob();
2106:        const file = new File(
2107:            [blob], 
2108:            filePath.split('/').pop(), 
2109:            { type: mimeType }
2110:        );
2111:        
2112:        console.log('Created file object:', file);
2113:        
2114:        // Process the file using our standard processors
2115:        let processedData;
2116:        if (fileType === 'pdf') {
2117:            processedData = await processPDF(file);
2118:            if (!processedData.success) {
2119:                throw new Error(processedData.error || 'Failed to process PDF');
2120:            }
2121:            
2122:            // Also display the PDF preview
2123:            displayPdfFromArrayBuffer(await blob.arrayBuffer(), file.name);
2124:        } else if (['jpg', 'jpeg', 'png', 'gif'].includes(fileType)) {
2125:            processedData = await processImage(file);
2126:            displayImagePreview(file);
2127:        } else {
2128:            processedData = await processTextFile(file);
2129:            displayTextPreview(file);
2130:        }
2131:        
2132:        // Store the processed file data
2133:        currentFile = file;
2134:        window.extractedText = processedData.text || '';
2135:        
2136:        // Show the file preview container
2137:        document.getElementById('filePreview').style.display = 'block';
2138:        
2139:        // Auto-select appropriate analysis type
2140:        autoSelectAnalysisType(file);
2141:        
2142:        // Add to document collection if not already present
2143:        if (!window.documentCollection) {
2144:            window.documentCollection = [];
2145:        }
2146:        
2147:        // Check if document already exists in collection
2148:        const existingDocIndex = window.documentCollection.findIndex(doc => 
2149:            doc.name === file.name
2150:        );
2151:        
2152:        if (existingDocIndex === -1) {
2153:            // Add to document collection
2154:            window.documentCollection.push({
2155:                id: `doc-${Date.now()}`,
2156:                name: file.name,
2157:                type: file.type,
2158:                size: file.size,
2159:                processingDate: new Date(),
2160:                text: processedData.text || '',
2161:                pageCount: processedData.pageCount || 1,
2162:                metadata: processedData.metadata || {}
2163:            });
2164:            
2165:            // Update document list in sidebar
2166:            updateDocumentList();
2167:            
2168:            showToast(`${file.name} added to your document collection`, 'success');
2169:        } else {
2170:            showToast(`${file.name} loaded for analysis`, 'info');
2171:        }
2172:        
2173:    } catch (error) {
2174:        console.error('Error viewing sample file:', error);
2175:        // More user-friendly error message
2176:        showToast(`Sample file is loading, please wait a moment and try again.`, 'info');
2177:    }
2178:}
2179:
2180:function getFileExtension(filename) {
2181:    return filename.split('.').pop().toLowerCase();
2182:}
2183:
2184:function initConfirmationDialog() {
2185:    const startAnalysisBtn = document.getElementById('startAnalysisBtn');
2186:    const analysisConfirmation = document.getElementById('analysisConfirmation');
2187:    const confirmAnalysisBtn = document.getElementById('confirmAnalysisBtn');
2188:    const cancelAnalysisBtn = document.getElementById('cancelAnalysisBtn');
2189:    const closeConfirmDialog = document.getElementById('closeConfirmDialog');
2190:    
2191:    if (startAnalysisBtn && analysisConfirmation) {
2192:        startAnalysisBtn.addEventListener('click', showConfirmationDialog);
2193:        
2194:        if (confirmAnalysisBtn) {
2195:            confirmAnalysisBtn.addEventListener('click', () => {
2196:                analysisConfirmation.style.display = 'none';
2197:                analyzeContent();
2198:            });
2199:        }
2200:        
2201:        if (cancelAnalysisBtn) {
2202:            cancelAnalysisBtn.addEventListener('click', () => {
2203:                analysisConfirmation.style.display = 'none';
2204:            });
2205:        }
2206:        
2207:        if (closeConfirmDialog) {
2208:            closeConfirmDialog.addEventListener('click', () => {
2209:                analysisConfirmation.style.display = 'none';
2210:            });
2211:        }
2212:    }
2213:}
2214:
2215:function showConfirmationDialog() {
2216:    const analysisConfirmation = document.getElementById('analysisConfirmation');
2217:    const confirmFileName = document.getElementById('confirmFileName');
2218:    const confirmAnalysisType = document.getElementById('confirmAnalysisType');
2219:    const confirmOperation = document.getElementById('confirmOperation');
2220:    const confirmOcr = document.getElementById('confirmOcr');
2221:    const confirmCustomPrompt = document.getElementById('confirmCustomPrompt');
2222:    const customPromptPreview = document.getElementById('customPromptPreview');
2223:    
2224:    if (!currentFile) {
2225:        showToast('Please upload or select a document first', 'error');
2226:        return;
2227:    }
2228:    
2229:    // Set confirmation details
2230:    confirmFileName.textContent = currentFile.name || 'Unnamed document';
2231:    
2232:    // Get selected analysis type
2233:    const analysisTypeValue = document.querySelector('input[name="analysisType"]:checked').value;
2234:    confirmAnalysisType.textContent = analysisTypeValue === 'document' ? 'Document Analysis' : 'Image Description';
2235:    
2236:    // Get selected operation
2237:    const activeOptionBtn = document.querySelector('.option-btn.active');
2238:    if (activeOptionBtn) {
2239:        confirmOperation.textContent = activeOptionBtn.textContent;
2240:    } else {
2241:        confirmOperation.textContent = 'Custom Analysis';
2242:    }
2243:    
2244:    // Check if OCR is enabled
2245:    const ocrToggle = document.getElementById('ocrToggle');
2246:    confirmOcr.textContent = ocrToggle && ocrToggle.checked ? 'Yes' : 'No';
2247:    
2248:    // Handle custom prompt
2249:    if (isCustomPrompt) {
2250:        const customPromptText = document.getElementById('customPrompt').value;
2251:        customPromptPreview.textContent = customPromptText || 'No custom prompt provided';
2252:        confirmCustomPrompt.style.display = 'block';
2253:    } else {
2254:        confirmCustomPrompt.style.display = 'none';
2255:    }
2256:    
2257:    // Show the confirmation dialog with animation
2258:    analysisConfirmation.style.display = 'flex';
2259:    setTimeout(() => {
2260:        analysisConfirmation.classList.add('visible');
2261:    }, 10);
2262:}
2263:
2264:function initKeyboardShortcuts() {
2265:    document.addEventListener('keydown', handleKeyboardShortcut);
2266:    
2267:    // Bind keyboard shortcuts help dialog
2268:    const quickHelp = document.getElementById('quickHelp');
2269:    const keyboardShortcuts = document.getElementById('keyboardShortcuts');
2270:    const closeShortcutsBtn = document.getElementById('closeShortcutsBtn');
2271:    
2272:    if (quickHelp && keyboardShortcuts) {
2273:        quickHelp.addEventListener('click', () => {
2274:            keyboardShortcuts.style.display = 'flex';
2275:            setTimeout(() => {
2276:                keyboardShortcuts.classList.add('visible');
2277:            }, 10);
2278:        });
2279:        
2280:        if (closeShortcutsBtn) {
2281:            closeShortcutsBtn.addEventListener('click', () => {
2282:                keyboardShortcuts.classList.remove('visible');
2283:                setTimeout(() => {
2284:                    keyboardShortcuts.style.display = 'none';
2285:        }, 300);
2286:    });
2287:        }
2288:    }
2289:}
2290:
2291:function handleKeyboardShortcut(e) {
2292:    // Ctrl + O: Open file
2293:    if (e.ctrlKey && e.key === 'o') {
2294:        e.preventDefault();
2295:        document.getElementById('fileInput').click();
2296:    }
2297:    
2298:    // Ctrl + Enter: Start Analysis
2299:    if (e.ctrlKey && e.key === 'Enter') {
2300:        e.preventDefault();
2301:        if (currentFile) {
2302:            showConfirmationDialog();
2303:        } else {
2304:            showToast('Please upload or select a document first', 'error');
2305:        }
2306:    }
2307:    
2308:    // Ctrl + S: Save analysis results
2309:    if (e.ctrlKey && e.key === 's') {
2310:        e.preventDefault();
2311:        const results = document.querySelector('.results-section');
2312:        if (results && results.style.display !== 'none') {
2313:            document.getElementById('saveToCloud').click();
2314:        }
2315:    }
2316:    
2317:    // Alt + 1-5: Select analysis options
2318:    if (e.altKey && ['1','2','3','4','5'].includes(e.key)) {
2319:        e.preventDefault();
2320:        const index = parseInt(e.key) - 1;
2321:        const options = document.querySelectorAll('.option-btn:not(.highlight-option)');
2322:        if (options[index]) {
2323:            options[index].click();
2324:        }
2325:    }
2326:    
2327:    // ESC: Close dialogs
2328:    if (e.key === 'Escape') {
2329:        const confirmDialog = document.getElementById('analysisConfirmation');
2330:        const shortcutsDialog = document.getElementById('keyboardShortcuts');
2331:        
2332:        if (confirmDialog && confirmDialog.style.display !== 'none') {
2333:            confirmDialog.classList.remove('visible');
2334:            setTimeout(() => {
2335:                confirmDialog.style.display = 'none';
2336:            }, 300);
2337:        }
2338:        
2339:        if (shortcutsDialog && shortcutsDialog.style.display !== 'none') {
2340:            shortcutsDialog.classList.remove('visible');
2341:            setTimeout(() => {
2342:                shortcutsDialog.style.display = 'none';
2343:            }, 300);
2344:        }
2345:    }
2346:    
2347:    // ?: Show keyboard shortcuts
2348:    if (e.key === '?' || (e.shiftKey && e.key === '/')) {
2349:        e.preventDefault();
2350:        const shortcutsDialog = document.getElementById('keyboardShortcuts');
2351:        if (shortcutsDialog) {
2352:            shortcutsDialog.style.display = 'flex';
2353:            setTimeout(() => {
2354:                shortcutsDialog.classList.add('visible');
2355:            }, 10);
2356:        }
2357:    }
2358:}
2359:
2360:function initQuickActions() {
2361:    const quickFullscreen = document.getElementById('quickFullscreen');
2362:    
2363:    if (quickFullscreen) {
2364:        quickFullscreen.addEventListener('click', () => {
2365:            toggleFullscreen('preview');
2366:        });
2367:    }
2368:}
2369:
2370:function toggleDarkMode() {
2371:    darkMode = !darkMode;
2372:    document.body.classList.toggle('dark-mode', darkMode);
2373:    
2374:    // Store preference
2375:    localStorage.setItem('darkMode', darkMode ? 'true' : 'false');
2376:    
2377:    // Show feedback
2378:    showToast(`Dark mode ${darkMode ? 'enabled' : 'disabled'}`, 'info');
2379:}
2380:
2381:// Save analysis to history
2382:function saveAnalysisToHistory(analysisData) {
2383:    // Add a unique ID if not present
2384:    if (!analysisData.id) {
2385:        analysisData.id = 'analysis-' + Date.now();
2386:    }
2387:    
2388:    console.log('Saving analysis to history:', analysisData);
2389:    
2390:    // Get existing history from localStorage
2391:    let analysisHistory = JSON.parse(localStorage.getItem('analysisHistory')) || [];
2392:    
2393:    // Add the new analysis at the beginning of the array
2394:    analysisHistory.unshift(analysisData);
2395:    
2396:    // Limit the history to 10 items to prevent localStorage from getting too full
2397:    if (analysisHistory.length > 10) {
2398:        analysisHistory = analysisHistory.slice(0, 10);
2399:    }
2400:    
2401:    // Save back to localStorage
2402:    localStorage.setItem('analysisHistory', JSON.stringify(analysisHistory));
2403:    
2404:    // Update the history display
2405:    updateHistoryDisplay();
2406:    
2407:    console.log('Analysis saved to history successfully');
2408:}
2409:
2410:// Initialize the PDF preview with the provided PDF document
2411:window.renderPdfPreview = function(pdf, initialPage = 1) {
2412:    console.log(`Initializing PDF preview: ${pdf.numPages} pages total`);
2413:    
2414:    // Store PDF state in window variables for access across functions
2415:    window.pdfDocument = pdf;
2416:    window.currentPdfPage = initialPage;
2417:    
2418:    // Render the initial page
2419:    renderPdfPage(pdf, initialPage);
2420:    
2421:    // Enable or disable page navigation buttons based on current page
2422:    const prevPageBtn = document.getElementById('prevPage');
2423:    const nextPageBtn = document.getElementById('nextPage');
2424:    
2425:    if (prevPageBtn) {
2426:        prevPageBtn.disabled = initialPage <= 1;
2427:    }
2428:    
2429:    if (nextPageBtn) {
2430:        nextPageBtn.disabled = initialPage >= pdf.numPages;
2431:    }
2432:    
2433:    // Update page info
2434:    const pageInfo = document.getElementById('pageInfo');
2435:    if (pageInfo) {
2436:        pageInfo.textContent = `Page ${initialPage} of ${pdf.numPages}`;
2437:    }
2438:};
2439:
2440:// Function to toggle fullscreen for preview
2441:function toggleFullscreen(previewType) {
2442:    const previewContainer = document.getElementById('filePreview');
2443:    const pdfPreview = document.getElementById('pdfPreview');
2444:    const imagePreview = document.getElementById('imagePreview');
2445:    
2446:    // Get the specific element to toggle
2447:    let targetElement;
2448:    
2449:    if (previewType === 'pdf') {
2450:        targetElement = pdfPreview;
2451:    } else if (previewType === 'image') {
2452:        targetElement = imagePreview;
2453:    } else {
2454:        return;
2455:    }
2456:    
2457:    // Check if already in fullscreen
2458:    if (targetElement.classList.contains('fullscreen-preview')) {
2459:        // Exit fullscreen mode
2460:        targetElement.classList.remove('fullscreen-preview');
2461:        previewContainer.classList.remove('has-fullscreen');
2462:        
2463:        // Update button text
2464:        const fullscreenBtn = targetElement.querySelector('.fullscreen-btn');
2465:        if (fullscreenBtn) {
2466:            fullscreenBtn.innerHTML = `
2467:                <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
2468:                    <path d="M8 3H5a2 2 0 0 0-2 2v3m18 0V5a2 2 0 0 0-2-2h-3m0 18h3a2 2 0 0 0 2-2v-3M3 16v3a2 2 0 0 0 2 2h3"></path>
2469:                </svg>
2470:                <span>Fullscreen</span>
2471:            `;
2472:        }
2473:        
2474:        // Scroll to the preview container
2475:        previewContainer.scrollIntoView({ behavior: 'smooth' });
2476:    } else {
2477:        // Enter fullscreen mode
2478:        targetElement.classList.add('fullscreen-preview');
2479:        previewContainer.classList.add('has-fullscreen');
2480:        
2481:        // Update button text
2482:        const fullscreenBtn = targetElement.querySelector('.fullscreen-btn');
2483:        if (fullscreenBtn) {
2484:            fullscreenBtn.innerHTML = `
2485:                <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
2486:                    <path d="M8 3v3a2 2 0 0 1-2 2H3m18 0h-3a2 2 0 0 1-2-2V3m0 18v-3a2 2 0 0 1 2-2h3M3 16h3a2 2 0 0 1 2 2v3"></path>
2487:                </svg>
2488:                <span>Exit Fullscreen</span>
2489:            `;
2490:        }
2491:        
2492:        // Scroll to the top of the fullscreen element
2493:        targetElement.scrollIntoView({ behavior: 'smooth' });
2494:    }
2495:    
2496:    // If it's a PDF preview, resize the canvas to fit the new container size
2497:    if (previewType === 'pdf' && window.pdfDocument && window.currentPdfPage) {
2498:        // Give a small delay to allow the transition to complete
2499:        setTimeout(() => {
2500:            renderPdfPage(window.pdfDocument, window.currentPdfPage);
2501:        }, 300);
2502:    }
2503:}
2504:
2505:// Initialize settings in the app
2506:function initializeSettings() {
2507:    // Create settings UI
2508:    const settingsContainer = document.createElement('div');
2509:    settingsContainer.className = 'settings-panel';
2510:    settingsContainer.innerHTML = `
2511:        <div class="settings-header">
2512:            <h3>Settings</h3>
2513:            <button class="close-btn settings-close"></button>
2514:        </div>
2515:        <div class="settings-content">
2516:            <div class="settings-section">
2517:                <h4>Appearance</h4>
2518:                <div class="setting-item">
2519:                    <label for="darkModeToggle">Dark Mode</label>
2520:                    <div class="toggle-switch">
2521:                        <input type="checkbox" id="darkModeToggle">
2522:                        <span class="toggle-slider"></span>
2523:                    </div>
2524:                </div>
2525:                <div class="setting-item">
2526:                    <label for="largeFontToggle">Larger Font Size</label>
2527:                    <div class="toggle-switch">
2528:                        <input type="checkbox" id="largeFontToggle">
2529:                        <span class="toggle-slider"></span>
2530:                    </div>
2531:                </div>
2532:            </div>
2533:            
2534:            <div class="settings-section">
2535:                <h4>Preview Options</h4>
2536:                <div class="setting-item">
2537:                    <label for="previewSizeRange">Default Preview Size</label>
2538:                    <input type="range" id="previewSizeRange" min="300" max="700" step="50" value="500">
2539:                    <span id="previewSizeValue">500px</span>
2540:                </div>
2541:                <div class="setting-item">
2542:                    <label for="pdfScaleRange">PDF Zoom Level</label>
2543:                    <input type="range" id="pdfScaleRange" min="1" max="2" step="0.1" value="1.5">
2544:                    <span id="pdfScaleValue">1.5x</span>
2545:                </div>
2546:            </div>
2547:            
2548:            <div class="settings-section">
2549:                <h4>Document Analysis</h4>
2550:                <div class="setting-item">
2551:                    <label for="ocrToggleSettings">Enable OCR by default</label>
2552:                    <div class="toggle-switch">
2553:                        <input type="checkbox" id="ocrToggleSettings" checked>
2554:                        <span class="toggle-slider"></span>
2555:                    </div>
2556:                </div>
2557:                <div class="setting-item">
2558:                    <label for="autoAnalyzeToggle">Auto-analyze after upload</label>
2559:                    <div class="toggle-switch">
2560:                        <input type="checkbox" id="autoAnalyzeToggle">
2561:                        <span class="toggle-slider"></span>
2562:                    </div>
2563:                </div>
2564:            </div>
2565:        </div>
2566:        <div class="settings-footer">
2567:            <button id="resetSettings" class="action-btn">Reset to Defaults</button>
2568:            <button id="saveSettings" class="action-btn">Save Changes</button>
2569:        </div>
2570:    `;
2571:    
2572:    document.body.appendChild(settingsContainer);
2573:    
2574:    // Create settings toggle button in the header
2575:    const headerElement = document.querySelector('header');
2576:    if (headerElement) {
2577:        const settingsBtn = document.createElement('button');
2578:        settingsBtn.className = 'settings-toggle-btn';
2579:        settingsBtn.innerHTML = `
2580:            <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
2581:                <circle cx="12" cy="12" r="3"></circle>
2582:                <path d="M19.4 15a1.65 1.65 0 0 0 .33 1.82l.06.06a2 2 0 0 1 0 2.83 2 2 0 0 1-2.83 0l-.06-.06a1.65 1.65 0 0 0-1.82-.33 1.65 1.65 0 0 0-1 1.51V21a2 2 0 0 1-2 2 2 2 0 0 1-2-2v-.09A1.65 1.65 0 0 0 9 19.4a1.65 1.65 0 0 0-1.82.33l-.06.06a2 2 0 0 1-2.83 0 2 2 0 0 1 0-2.83l.06-.06a1.65 1.65 0 0 0 .33-1.82 1.65 1.65 0 0 0-1.51-1H3a2 2 0 0 1-2-2 2 2 0 0 1 2-2h.09A1.65 1.65 0 0 0 4.6 9a1.65 1.65 0 0 0-.33-1.82l-.06-.06a2 2 0 0 1 0-2.83 2 2 0 0 1 2.83 0l.06.06a1.65 1.65 0 0 0 1.82.33H9a1.65 1.65 0 0 0 1-1.51V3a2 2 0 0 1 2-2 2 2 0 0 1 2 2v.09a1.65 1.65 0 0 0 1 1.51 1.65 1.65 0 0 0 1.82-.33l.06-.06a2 2 0 0 1 2.83 0 2 2 0 0 1 0 2.83l-.06.06a1.65 1.65 0 0 0-.33 1.82V9a1.65 1.65 0 0 0 1.51 1H21a2 2 0 0 1 2 2 2 2 0 0 1-2 2h-.09a1.65 1.65 0 0 0-1.51 1z"></path>
2583:            </svg>
2584:        `;
2585:        headerElement.appendChild(settingsBtn);
2586:        
2587:        // Add click event listener to the settings button
2588:        settingsBtn.addEventListener('click', toggleSettings);
2589:    }
2590:    
2591:    // Load saved settings
2592:    loadSettings();
2593:    
2594:    // Add event listeners
2595:    document.querySelector('.settings-close').addEventListener('click', toggleSettings);
2596:    document.getElementById('saveSettings').addEventListener('click', saveSettings);
2597:    document.getElementById('resetSettings').addEventListener('click', resetSettings);
2598:    
2599:    // Add event listeners for range inputs
2600:    const previewSizeRange = document.getElementById('previewSizeRange');
2601:    const previewSizeValue = document.getElementById('previewSizeValue');
2602:    if (previewSizeRange && previewSizeValue) {
2603:        previewSizeRange.addEventListener('input', function() {
2604:            previewSizeValue.textContent = this.value + 'px';
2605:            updatePreviewSize(this.value);
2606:        });
2607:    }
2608:    
2609:    const pdfScaleRange = document.getElementById('pdfScaleRange');
2610:    const pdfScaleValue = document.getElementById('pdfScaleValue');
2611:    if (pdfScaleRange && pdfScaleValue) {
2612:        pdfScaleRange.addEventListener('input', function() {
2613:            pdfScaleValue.textContent = this.value + 'x';
2614:            updatePdfScale(this.value);
2615:        });
2616:    }
2617:    
2618:    // Add event listener for dark mode toggle
2619:    const darkModeToggle = document.getElementById('darkModeToggle');
2620:    if (darkModeToggle) {
2621:        darkModeToggle.addEventListener('change', function() {
2622:            toggleDarkMode(this.checked);
2623:        });
2624:    }
2625:    
2626:    // Add event listener for font size toggle
2627:    const largeFontToggle = document.getElementById('largeFontToggle');
2628:    if (largeFontToggle) {
2629:        largeFontToggle.addEventListener('change', function() {
2630:            toggleLargeFont(this.checked);
2631:        });
2632:    }
2633:    
2634:    // Add event listener for OCR toggle
2635:    const ocrToggleSettings = document.getElementById('ocrToggleSettings');
2636:    const ocrToggle = document.getElementById('ocrToggle');
2637:    if (ocrToggleSettings && ocrToggle) {
2638:        ocrToggleSettings.addEventListener('change', function() {
2639:            ocrToggle.checked = this.checked;
2640:        });
2641:        // Sync the two OCR toggles
2642:        ocrToggle.addEventListener('change', function() {
2643:            ocrToggleSettings.checked = this.checked;
2644:        });
2645:    }
2646:}
2647:
2648:// Function to toggle settings panel visibility
2649:function toggleSettings() {
2650:    const settingsPanel = document.querySelector('.settings-panel');
2651:    if (settingsPanel) {
2652:        settingsPanel.classList.toggle('visible');
2653:    }
2654:}
2655:
2656:// Function to save settings
2657:function saveSettings() {
2658:    const settings = {
2659:        darkMode: document.getElementById('darkModeToggle').checked,
2660:        largeFont: document.getElementById('largeFontToggle').checked,
2661:        previewSize: document.getElementById('previewSizeRange').value,
2662:        pdfScale: document.getElementById('pdfScaleRange').value,
2663:        ocrEnabled: document.getElementById('ocrToggleSettings').checked,
2664:        autoAnalyze: document.getElementById('autoAnalyzeToggle').checked
2665:    };
2666:    
2667:    // Save to localStorage
2668:    localStorage.setItem('documentAnalyzerSettings', JSON.stringify(settings));
2669:    
2670:    // Apply settings
2671:    applySettings(settings);
2672:    
2673:    // Show confirmation
2674:    showToast('Settings saved successfully', 'success');
2675:    
2676:    // Close settings panel
2677:    toggleSettings();
2678:}
2679:
2680:// Function to load settings
2681:function loadSettings() {
2682:    try {
2683:        console.log('Loading saved settings...');
2684:        
2685:        // Get saved settings from localStorage
2686:        const savedSettings = localStorage.getItem('documentAnalyzerSettings');
2687:        if (!savedSettings) {
2688:            console.log('No saved settings found, using defaults');
2689:            return;
2690:        }
2691:        
2692:        // Parse the saved settings
2693:        const settings = JSON.parse(savedSettings);
2694:        console.log('Found saved settings:', settings);
2695:        
2696:        // Apply the settings to the UI
2697:        applySettings(settings);
2698:        
2699:        return settings;
2700:    } catch (error) {
2701:        console.error('Error loading settings:', error);
2702:        // Don't throw the error, just use defaults
2703:        return null;
2704:    }
2705:}
2706:
2707:// Function to reset settings to defaults
2708:function resetSettings() {
2709:    const defaultSettings = {
2710:        darkMode: false,
2711:        largeFont: false,
2712:        previewSize: 500,
2713:        pdfScale: 1.5,
2714:        ocrEnabled: true,
2715:        autoAnalyze: false
2716:    };
2717:    
2718:    // Update UI with default settings
2719:    document.getElementById('darkModeToggle').checked = defaultSettings.darkMode;
2720:    document.getElementById('largeFontToggle').checked = defaultSettings.largeFont;
2721:    document.getElementById('previewSizeRange').value = defaultSettings.previewSize;
2722:    document.getElementById('previewSizeValue').textContent = defaultSettings.previewSize + 'px';
2723:    document.getElementById('pdfScaleRange').value = defaultSettings.pdfScale;
2724:    document.getElementById('pdfScaleValue').textContent = defaultSettings.pdfScale + 'x';
2725:    document.getElementById('ocrToggleSettings').checked = defaultSettings.ocrEnabled;
2726:    document.getElementById('ocrToggle').checked = defaultSettings.ocrEnabled;
2727:    document.getElementById('autoAnalyzeToggle').checked = defaultSettings.autoAnalyze;
2728:    
2729:    // Apply default settings
2730:    applySettings(defaultSettings);
2731:    
2732:    // Show confirmation
2733:    showToast('Settings reset to defaults', 'info');
2734:}
2735:
2736:// Function to apply settings
2737:function applySettings(settings) {
2738:    if (!settings) return;
2739:    
2740:    console.log('Applying settings to UI...');
2741:    
2742:    try {
2743:        // Apply dark mode setting
2744:        const darkModeEnabled = settings.darkMode || false;
2745:        if (darkModeEnabled) {
2746:            document.body.classList.add('dark-mode');
2747:        } else {
2748:            document.body.classList.remove('dark-mode');
2749:        }
2750:        
2751:        // Apply large font setting
2752:        const largeFontEnabled = settings.largeFont || false;
2753:        if (largeFontEnabled) {
2754:            document.body.classList.add('large-font');
2755:        } else {
2756:            document.body.classList.remove('large-font');
2757:        }
2758:        
2759:        // Apply OCR toggle
2760:        const ocrToggle = document.getElementById('ocrToggle');
2761:        if (ocrToggle && 'ocrEnabled' in settings) {
2762:            ocrToggle.checked = settings.ocrEnabled;
2763:        }
2764:        
2765:        // Apply theme preference to the toggle
2766:        const themeToggle = document.getElementById('themeToggle');
2767:        if (themeToggle && 'darkMode' in settings) {
2768:            themeToggle.checked = settings.darkMode;
2769:        }
2770:        
2771:        // Apply large font preference to the toggle
2772:        const fontToggle = document.getElementById('fontSizeToggle');
2773:        if (fontToggle && 'largeFont' in settings) {
2774:            fontToggle.checked = settings.largeFont;
2775:        }
2776:        
2777:        // Apply preview size
2778:        const previewSizeControl = document.getElementById('previewSizeControl');
2779:        if (previewSizeControl && 'previewSize' in settings) {
2780:            previewSizeControl.value = settings.previewSize;
2781:            updatePreviewSize(settings.previewSize);
2782:        }
2783:        
2784:        // Apply PDF scale
2785:        const pdfScaleControl = document.getElementById('pdfScaleControl');
2786:        if (pdfScaleControl && 'pdfScale' in settings) {
2787:            pdfScaleControl.value = settings.pdfScale;
2788:            updatePdfScale(settings.pdfScale);
2789:        }
2790:        
2791:        console.log('Settings applied successfully');
2792:    } catch (error) {
2793:        console.error('Error applying settings:', error);
2794:        // Continue execution even if there's an error
2795:    }
2796:}
2797:
2798:// Toggle dark mode
2799:function toggleDarkMode(enabled) {
2800:    if (enabled) {
2801:        document.body.classList.add('dark-mode');
2802:    } else {
2803:        document.body.classList.remove('dark-mode');
2804:    }
2805:}
2806:
2807:// Toggle large font
2808:function toggleLargeFont(enabled) {
2809:    if (enabled) {
2810:        document.body.classList.add('large-font');
2811:    } else {
2812:        document.body.classList.remove('large-font');
2813:    }
2814:}
2815:
2816:// Update preview size
2817:function updatePreviewSize(size) {
2818:    const previewContent = document.querySelector('.preview-content');
2819:    if (previewContent) {
2820:        previewContent.style.height = `${size}px`;
2821:    }
2822:    
2823:    // If a PDF is currently being viewed, redraw it to fit the new size
2824:    if (window.pdfDocument && window.currentPdfPage) {
2825:        setTimeout(() => {
2826:            renderPdfPage(window.pdfDocument, window.currentPdfPage);
2827:        }, 50);
2828:    }
2829:}
2830:
2831:// Update PDF scale
2832:function updatePdfScale(scale) {
2833:    window.pdfScale = parseFloat(scale);
2834:    
2835:    // If a PDF is currently being viewed, redraw it with the new scale
2836:    if (window.pdfDocument && window.currentPdfPage) {
2837:        setTimeout(() => {
2838:            renderPdfPage(window.pdfDocument, window.currentPdfPage);
2839:        }, 50);
2840:    }
2841:}
2842:
2843:// Setup file upload event listeners
2844:function setupFileUploadEvents() {
2845:    // Initialize drag and drop functionality
2846:    const dropArea = document.getElementById('dropArea');
2847:    const fileInput = document.getElementById('fileInput');
2848:    const browseBtn = document.getElementById('browseBtn');
2849:    
2850:    // Ensure we have the required elements
2851:    if (!dropArea || !fileInput || !browseBtn) {
2852:        console.error('Required elements not found for file upload');
2853:        return;
2854:    }
2855:    
2856:    // Handle file input change
2857:    fileInput.addEventListener('change', function(e) {
2858:        e.preventDefault();
2859:        e.stopPropagation();
2860:        
2861:        console.log('File input change detected');
2862:        if (this.files && this.files.length > 0) {
2863:            console.log('Files selected:', this.files[0].name);
2864:            handleFiles(this.files);
2865:            // Reset the file input so the same file can be selected again
2866:            this.value = '';
2867:        }
2868:    });
2869:    
2870:    // Handle browse button click
2871:    browseBtn.addEventListener('click', function(e) {
2872:        e.preventDefault();
2873:        e.stopPropagation();
2874:        console.log('Browse button clicked');
2875:        fileInput.click();
2876:    });
2877:    
2878:    // Handle drag and drop events
2879:    dropArea.addEventListener('dragover', function(e) {
2880:        e.preventDefault();
2881:        e.stopPropagation();
2882:        this.classList.add('drag-over');
2883:    });
2884:    
2885:    dropArea.addEventListener('dragleave', function(e) {
2886:        e.preventDefault();
2887:        e.stopPropagation();
2888:        this.classList.remove('drag-over');
2889:    });
2890:    
2891:    dropArea.addEventListener('drop', function(e) {
2892:        e.preventDefault();
2893:        e.stopPropagation();
2894:        this.classList.remove('drag-over');
2895:        
2896:        const files = e.dataTransfer.files;
2897:        if (files.length > 0) {
2898:            console.log('Files dropped:', files[0].name);
2899:            handleFiles(files);
2900:        }
2901:    });
2902:    
2903:    // Handle drop area click (excluding buttons)
2904:    dropArea.addEventListener('click', function(e) {
2905:        // Don't trigger if we're clicking on a button or link inside the drop area
2906:        if (e.target.closest('.upload-btn') || e.target.closest('button') || e.target.closest('a')) {
2907:            return;
2908:        }
2909:        
2910:        console.log('Drop area clicked');
2911:        fileInput.click();
2912:    });
2913:}
2914:
2915:// Setup UI elements and interactions
2916:function setupUIElements() {
2917:    // Log available UI elements for debugging
2918:    console.log('Setting up UI elements');
2919:    
2920:    const startAnalysisBtn = document.getElementById('startAnalysisBtn');
2921:    if (startAnalysisBtn) {
2922:        console.log('Found start analysis button');
2923:    } else {
2924:        console.warn('Start analysis button not found');
2925:    }
2926:    
2927:    // Update copyright year
2928:    const currentYear = new Date().getFullYear();
2929:    const copyrightEl = document.getElementById('copyrightText');
2930:    if (copyrightEl) {
2931:        copyrightEl.textContent = ` 2025 Mithun. All Rights Reserved.`;
2932:    }
2933:}
2934:
2935:// Setup validation for required fields
2936:function setupValidation() {
2937:    // Example validation for custom prompt
2938:    const customPrompt = document.getElementById('customPrompt');
2939:    const startAnalysisBtn = document.getElementById('startAnalysisBtn');
2940:    
2941:    if (customPrompt && startAnalysisBtn) {
2942:        customPrompt.addEventListener('input', function() {
2943:            if (isCustomPrompt && this.value.trim() === '') {
2944:                startAnalysisBtn.setAttribute('disabled', 'disabled');
2945:                startAnalysisBtn.title = 'Please enter a custom prompt';
2946:            } else {
2947:                startAnalysisBtn.removeAttribute('disabled');
2948:                startAnalysisBtn.title = '';
2949:            }
2950:        });
2951:        console.log('Custom prompt validation initialized');
2952:    }
2953:}
2954:
2955:// Setup action buttons for Copy, Download, Share, Save in results
2956:function setupResultActionButtons() {
2957:    console.log('Setting up result action buttons');
2958:    
2959:    // Copy results button
2960:    const copyResultsBtn = document.getElementById('copyResults');
2961:    if (copyResultsBtn) {
2962:        copyResultsBtn.addEventListener('click', () => {
2963:            const resultsContent = document.getElementById('resultsContent');
2964:            if (resultsContent) {
2965:                // Create a range and select the content
2966:                const range = document.createRange();
2967:                range.selectNode(resultsContent);
2968:                window.getSelection().removeAllRanges();
2969:                window.getSelection().addRange(range);
2970:                
2971:                // Execute copy command
2972:                try {
2973:                    document.execCommand('copy');
2974:                    window.getSelection().removeAllRanges();
2975:                    showToast('Results copied to clipboard', 'success');
2976:                } catch (err) {
2977:                    console.error('Failed to copy text: ', err);
2978:                    showToast('Failed to copy text', 'error');
2979:                }
2980:            }
2981:        });
2982:    }
2983:    
2984:    // Download results button
2985:    const downloadResultsBtn = document.getElementById('downloadResults');
2986:    if (downloadResultsBtn) {
2987:        downloadResultsBtn.addEventListener('click', () => {
2988:            const resultsContent = document.getElementById('resultsContent');
2989:            if (resultsContent && window.analysisResults) {
2990:                try {
2991:                    // Create a blob with the text content
2992:                    const blob = new Blob([window.analysisResults], { type: 'text/plain' });
2993:                    const url = URL.createObjectURL(blob);
2994:                    
2995:                    // Create a temporary anchor and trigger download
2996:                    const a = document.createElement('a');
2997:                    a.href = url;
2998:                    a.download = `analysis-${new Date().toISOString().split('T')[0]}.txt`;
2999:                    document.body.appendChild(a);
3000:                    a.click();
3001:                    
3002:                    // Clean up
3003:                    document.body.removeChild(a);
3004:                    URL.revokeObjectURL(url);
3005:                    
3006:                    showToast('Results downloaded', 'success');
3007:                } catch (err) {
3008:                    console.error('Failed to download results: ', err);
3009:                    showToast('Failed to download results', 'error');
3010:                }
3011:            }
3012:        });
3013:    }
3014:    
3015:    // Share results button
3016:    const shareResultsBtn = document.getElementById('shareResults');
3017:    if (shareResultsBtn) {
3018:        shareResultsBtn.addEventListener('click', () => {
3019:            if (window.analysisResults && navigator.share) {
3020:                // Use Web Share API if available
3021:                navigator.share({
3022:                    title: 'Document Analysis Results',
3023:                    text: window.analysisResults.substring(0, 5000) // Limit text length for sharing
3024:                })
3025:                .then(() => showToast('Shared successfully', 'success'))
3026:                .catch(err => {
3027:                    console.error('Error sharing: ', err);
3028:                    showToast('Unable to share results', 'error');
3029:                });
3030:            } else {
3031:                // Fallback for browsers without Web Share API
3032:                const resultsUrl = window.location.href;
3033:                
3034:                // Create a temporary input to copy the URL
3035:                const input = document.createElement('input');
3036:                input.value = resultsUrl;
3037:                document.body.appendChild(input);
3038:                input.select();
3039:                document.execCommand('copy');
3040:                document.body.removeChild(input);
3041:                
3042:                showToast('URL copied to clipboard. You can now share it manually.', 'info');
3043:            }
3044:        });
3045:    }
3046:    
3047:    // Save to cloud/history button
3048:    const saveToCloudBtn = document.getElementById('saveToCloud');
3049:    if (saveToCloudBtn) {
3050:        saveToCloudBtn.addEventListener('click', () => {
3051:            if (window.analysisResults && currentFile) {
3052:                saveAnalysisToHistory({
3053:                    documentName: currentFile.name || 'Document',
3054:                    analysisType: currentAnalysisOption || 'analysis',
3055:                    timestamp: new Date().toISOString(),
3056:                    results: window.analysisResults,
3057:                    id: 'analysis-' + Date.now()
3058:                });
3059:                
3060:                updateHistoryDisplay();
3061:                showToast('Analysis saved to history', 'success');
3062:            } else {
3063:                showToast('No analysis results to save', 'error');
3064:            }
3065:        });
3066:    }
3067:}
3068:
3069:// Add text-to-speech and translation functionality
3070:function initTextToSpeechAndTranslation() {
3071:    // Create the text-to-speech and translation section
3072:    const resultsSection = document.querySelector('.results-section');
3073:    const resultsContent = document.getElementById('resultsContent');
3074:    
3075:    if (!resultsSection || !resultsContent) {
3076:        console.error('Results section not found');
3077:        return;
3078:    }
3079:    
3080:    // Create a new container for TTS and translation
3081:    const advancedToolsContainer = document.createElement('div');
3082:    advancedToolsContainer.className = 'advanced-tools-container';
3083:    advancedToolsContainer.innerHTML = `
3084:        <div class="advanced-tools-header">
3085:            <h3>Text-to-Speech & Translation</h3>
3086:        </div>
3087:        <div class="advanced-tools-content">
3088:            <div class="tts-container">
3089:                <h4>Text-to-Speech</h4>
3090:                <div class="tts-controls">
3091:                    <select id="ttsVoiceSelect" class="voice-select">
3092:                        <option value="">Select a voice</option>
3093:                    </select>
3094:                    <div class="tts-buttons">
3095:                        <button id="ttsPlayBtn" class="tts-btn">
3096:                            <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
3097:                                <polygon points="5 3 19 12 5 21 5 3"></polygon>
3098:                            </svg>
3099:                            Play
3100:                        </button>
3101:                        <button id="ttsPauseBtn" class="tts-btn">
3102:                            <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
3103:                                <rect x="6" y="4" width="4" height="16"></rect>
3104:                                <rect x="14" y="4" width="4" height="16"></rect>
3105:                            </svg>
3106:                            Pause
3107:                        </button>
3108:                        <button id="ttsStopBtn" class="tts-btn">
3109:                            <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
3110:                                <rect x="3" y="3" width="18" height="18" rx="2" ry="2"></rect>
3111:                            </svg>
3112:                            Stop
3113:                        </button>
3114:                    </div>
3115:                </div>
3116:            </div>
3117:            
3118:            <div class="translation-container">
3119:                <h4>Translation</h4>
3120:                <div class="translation-controls">
3121:                    <select id="translationLanguage" class="language-select">
3122:                        <option value="">Select a language</option>
3123:                        <!-- Indian Languages -->
3124:                        <option value="hi">Hindi ()</option>
3125:                        <option value="bn">Bengali ()</option>
3126:                        <option value="te">Telugu ()</option>
3127:                        <option value="mr">Marathi ()</option>
3128:                        <option value="ta">Tamil ()</option>
3129:                        <option value="ur">Urdu ()</option>
3130:                        <option value="gu">Gujarati ()</option>
3131:                        <option value="kn">Kannada ()</option>
3132:                        <option value="ml">Malayalam ()</option>
3133:                        <option value="pa">Punjabi ()</option>
3134:                        <!-- Other Asian Languages -->
3135:                        <option value="zh">Chinese ()</option>
3136:                        <option value="ja">Japanese ()</option>
3137:                        <option value="ko">Korean ()</option>
3138:                        <option value="th">Thai ()</option>
3139:                        <option value="vi">Vietnamese (Ting Vit)</option>
3140:                        <!-- European Languages -->
3141:                        <option value="fr">French (Franais)</option>
3142:                        <option value="de">German (Deutsch)</option>
3143:                        <option value="es">Spanish (Espaol)</option>
3144:                        <option value="it">Italian (Italiano)</option>
3145:                        <option value="pt">Portuguese (Portugus)</option>
3146:                        <option value="ru">Russian ()</option>
3147:                        <option value="nl">Dutch (Nederlands)</option>
3148:                        <option value="sv">Swedish (Svenska)</option>
3149:                        <option value="pl">Polish (Polski)</option>
3150:                        <option value="tr">Turkish (Trke)</option>
3151:                        <!-- Middle Eastern Languages -->
3152:                        <option value="ar">Arabic ()</option>
3153:                        <option value="he">Hebrew ()</option>
3154:                        <option value="fa">Persian ()</option>
3155:                        <!-- African Languages -->
3156:                        <option value="sw">Swahili (Kiswahili)</option>
3157:                        <option value="am">Amharic ()</option>
3158:                        <option value="ha">Hausa (Hausa)</option>
3159:                        <!-- Other languages can be added here -->
3160:                    </select>
3161:                    <button id="translateBtn" class="translate-btn">Translate</button>
3162:                </div>
3163:                <div id="translationResult" class="translation-result"></div>
3164:            </div>
3165:        </div>
3166:    `;
3167:    
3168:    // Insert after results-content
3169:    resultsContent.parentNode.insertBefore(advancedToolsContainer, resultsContent.nextSibling);
3170:    
3171:    // Initialize text-to-speech functionality
3172:    initTextToSpeech();
3173:    
3174:    // Initialize translation functionality
3175:    initTranslation();
3176:}
3177:
3178:// Text-to-speech implementation
3179:function initTextToSpeech() {
3180:    // Get TTS elements
3181:    const ttsVoiceSelect = document.getElementById('ttsVoiceSelect');
3182:    const ttsPlayBtn = document.getElementById('ttsPlayBtn');
3183:    const ttsPauseBtn = document.getElementById('ttsPauseBtn');
3184:    const ttsStopBtn = document.getElementById('ttsStopBtn');
3185:    const resultsContent = document.getElementById('resultsContent');
3186:    
3187:    if (!ttsVoiceSelect || !ttsPlayBtn || !ttsPauseBtn || !ttsStopBtn || !resultsContent) {
3188:        console.error('TTS elements not found');
3189:        return;
3190:    }
3191:    
3192:    // Speech synthesis variables
3193:    let speech = null;
3194:    let voices = [];
3195:    
3196:    // Check if browser supports speech synthesis
3197:    if ('speechSynthesis' in window) {
3198:        // Get available voices
3199:        speech = window.speechSynthesis;
3200:        
3201:        // Force voice loading and population
3202:        function loadVoices() {
3203:            // Get all available voices
3204:            voices = speech.getVoices();
3205:            
3206:            // Log available voices for debugging
3207:            console.log('Available voices:', voices.length);
3208:            
3209:            // Clear existing options
3210:            ttsVoiceSelect.innerHTML = '<option value="">Select a voice</option>';
3211:            
3212:            // If no voices are available yet, try again in a moment
3213:            if (voices.length === 0) {
3214:                setTimeout(loadVoices, 100);
3215:                return;
3216:            }
3217:            
3218:            // Add available voices
3219:            voices.forEach(voice => {
3220:                const option = document.createElement('option');
3221:                option.value = voice.name;
3222:                option.textContent = `${voice.name} (${voice.lang})`;
3223:                option.setAttribute('data-lang', voice.lang);
3224:                ttsVoiceSelect.appendChild(option);
3225:            });
3226:            
3227:            // If we found voices, notify the user
3228:            if (voices.length > 0) {
3229:                console.log('Loaded', voices.length, 'voices');
3230:                showToast(`Loaded ${voices.length} text-to-speech voices`, 'info');
3231:            } else {
3232:                console.error('No voices available for speech synthesis');
3233:                showToast('No voices available for text-to-speech', 'error');
3234:            }
3235:        }
3236:        
3237:        // Initial loading - both methods to support different browsers
3238:        loadVoices();
3239:        
3240:        // Chrome loads voices asynchronously
3241:        if (speech.onvoiceschanged !== undefined) {
3242:            speech.onvoiceschanged = loadVoices;
3243:        }
3244:        
3245:        // Play button handler
3246:        ttsPlayBtn.addEventListener('click', () => {
3247:            if (speech.paused) {
3248:                speech.resume();
3249:            } else {
3250:                const text = resultsContent.textContent || '';
3251:                if (text.trim() === '') {
3252:                    showToast('No text to speak', 'error');
3253:                    return;
3254:                }
3255:                
3256:                const utterance = new SpeechSynthesisUtterance(text);
3257:                const selectedVoice = ttsVoiceSelect.value;
3258:                
3259:                if (selectedVoice) {
3260:                    utterance.voice = voices.find(voice => voice.name === selectedVoice);
3261:                }
3262:                
3263:                speech.speak(utterance);
3264:                showToast('Text-to-speech started', 'info');
3265:            }
3266:        });
3267:        
3268:        // Pause button handler
3269:        ttsPauseBtn.addEventListener('click', () => {
3270:            if (speech.speaking && !speech.paused) {
3271:                speech.pause();
3272:                showToast('Text-to-speech paused', 'info');
3273:            }
3274:        });
3275:        
3276:        // Stop button handler
3277:        ttsStopBtn.addEventListener('click', () => {
3278:            if (speech.speaking) {
3279:                speech.cancel();
3280:                showToast('Text-to-speech stopped', 'info');
3281:            }
3282:        });
3283:    } else {
3284:        // Hide TTS if not supported
3285:        const ttsContainer = document.querySelector('.tts-container');
3286:        if (ttsContainer) {
3287:            ttsContainer.innerHTML = '<p>Text-to-speech is not supported in your browser.</p>';
3288:        }
3289:    }
3290:}
3291:
3292:// Translation implementation
3293:function initTranslation() {
3294:    const translateBtn = document.getElementById('translateBtn');
3295:    const translationLanguage = document.getElementById('translationLanguage');
3296:    const translationResult = document.getElementById('translationResult');
3297:    const resultsContent = document.getElementById('resultsContent');
3298:    
3299:    if (!translateBtn || !translationLanguage || !translationResult || !resultsContent) {
3300:        console.error('Translation elements not found');
3301:        return;
3302:    }
3303:    
3304:    // Speech synthesis for translations
3305:    let speech = null;
3306:    let voices = [];
3307:    
3308:    // Check if browser supports speech synthesis
3309:    if ('speechSynthesis' in window) {
3310:        speech = window.speechSynthesis;
3311:        
3312:        // Force voice loading
3313:        function loadVoices() {
3314:            voices = speech.getVoices();
3315:            console.log('Translation voices loaded:', voices.length);
3316:            
3317:            // Group voices by language
3318:            const voicesByLang = {};
3319:            voices.forEach(voice => {
3320:                const lang = voice.lang.split('-')[0]; // Get main language code (e.g., 'en' from 'en-US')
3321:                if (!voicesByLang[lang]) {
3322:                    voicesByLang[lang] = [];
3323:                }
3324:                voicesByLang[lang].push(voice);
3325:            });
3326:            
3327:            console.log('Voices by language:', Object.keys(voicesByLang));
3328:        }
3329:        
3330:        // Initial loading
3331:        loadVoices();
3332:        
3333:        // Chrome loads voices asynchronously
3334:        if (speech.onvoiceschanged !== undefined) {
3335:            speech.onvoiceschanged = loadVoices;
3336:        }
3337:    }
3338:    
3339:    // Mock translation function (simulated for demo purposes)
3340:    translateBtn.addEventListener('click', () => {
3341:        const text = resultsContent.textContent || '';
3342:        const language = translationLanguage.value;
3343:        
3344:        if (!language) {
3345:            showToast('Please select a language', 'error');
3346:            return;
3347:        }
3348:        
3349:        if (text.trim() === '') {
3350:            showToast('No text to translate', 'error');
3351:            return;
3352:        }
3353:        
3354:        // Show loading indicator
3355:        translationResult.innerHTML = '<div class="translation-loading">Translating...</div>';
3356:        
3357:        // Simulate translation delay
3358:        setTimeout(() => {
3359:            // This is a mock translation - in a real app, you would call a translation API
3360:            const languageName = translationLanguage.options[translationLanguage.selectedIndex].text;
3361:            const translatedText = simulateTranslation(text, language);
3362:            
3363:            // Create speak button for the translation
3364:            const speakTranslationBtn = document.createElement('button');
3365:            speakTranslationBtn.className = 'translation-speak-btn';
3366:            speakTranslationBtn.innerHTML = `
3367:                <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
3368:                    <path d="M11 5L6 9H2v6h4l5 4V5z"></path>
3369:                    <path d="M19.07 4.93a10 10 0 0 1 0 14.14M15.54 8.46a5 5 0 0 1 0 7.07"></path>
3370:                </svg>
3371:                Speak
3372:            `;
3373:            
3374:            // Add click handler to speak the translation
3375:            speakTranslationBtn.addEventListener('click', () => {
3376:                if (!speech) {
3377:                    showToast('Text-to-speech is not supported in your browser', 'error');
3378:                    return;
3379:                }
3380:                
3381:                // Stop any ongoing speech
3382:                if (speech.speaking) {
3383:                    speech.cancel();
3384:                }
3385:                
3386:                // Create a new utterance for the translation
3387:                const utterance = new SpeechSynthesisUtterance(translatedText);
3388:                
3389:                // Try to find a voice for the selected language
3390:                const langCode = language.split('-')[0]; // Get the main language code
3391:                
3392:                // First try to find a voice that exactly matches the language
3393:                let matchingVoices = voices.filter(voice => 
3394:                    voice.lang.toLowerCase().startsWith(langCode.toLowerCase())
3395:                );
3396:                
3397:                // If no exact match, try to find any voice from the same language family
3398:                if (matchingVoices.length === 0) {
3399:                    // For Indian languages, try to find any Indian voice as fallback
3400:                    const indianLanguages = ['hi', 'bn', 'te', 'mr', 'ta', 'ur', 'gu', 'kn', 'ml', 'pa'];
3401:                    if (indianLanguages.includes(langCode)) {
3402:                        // Try Hindi as fallback for Indian languages
3403:                        matchingVoices = voices.filter(voice => 
3404:                            voice.lang.toLowerCase().startsWith('hi')
3405:                        );
3406:                    }
3407:                }
3408:                
3409:                if (matchingVoices.length > 0) {
3410:                    // Use the first matching voice
3411:                    utterance.voice = matchingVoices[0];
3412:                    console.log(`Using voice: ${utterance.voice.name} (${utterance.voice.lang})`);
3413:                } else {
3414:                    console.log(`No matching voice found for ${language}, using default voice`);
3415:                }
3416:                
3417:                // Set language regardless of voice match
3418:                utterance.lang = language;
3419:                
3420:                // Speak the translation
3421:                speech.speak(utterance);
3422:                showToast(`Speaking translation in ${languageName}`, 'info');
3423:            });
3424:            
3425:            translationResult.innerHTML = `
3426:                <div class="translation-header">
3427:                    <h5>Translated to ${languageName}</h5>
3428:                    <div class="translation-actions"></div>
3429:                </div>
3430:                <div class="translation-text">${translatedText}</div>
3431:            `;
3432:            
3433:            // Add speak button to the translation header
3434:            const translationActions = translationResult.querySelector('.translation-actions');
3435:            if (translationActions) {
3436:                translationActions.appendChild(speakTranslationBtn);
3437:            }
3438:            
3439:            showToast(`Text translated to ${languageName}`, 'success');
3440:        }, 1500);
3441:    });
3442:}
3443:
3444:// Function to simulate translation (for demo purposes)
3445:function simulateTranslation(text, language) {
3446:    // In a real application, you would call a translation API here
3447:    // For this demo, we'll just create a mock translated text
3448:    
3449:    // Get the first 100 characters as a sample
3450:    const sampleText = text.substring(0, Math.min(text.length, 100));
3451:    
3452:    // Create different patterns for different language groups
3453:    const langPatterns = {
3454:        // Indian languages
3455:        'hi': ['', '', ' ', '', ''],
3456:        'bn': ['', '', '', '', ''],
3457:        'te': ['', '', '', '', ''],
3458:        'ta': ['', '', '', '', ''],
3459:        
3460:        // European languages
3461:        'fr': ['Bonjour', 'Merci', 'Bienvenue', 'Bon', 'Important'],
3462:        'de': ['Hallo', 'Danke', 'Willkommen', 'Gut', 'Wichtig'],
3463:        'es': ['Hola', 'Gracias', 'Bienvenido', 'Bueno', 'Importante'],
3464:        
3465:        // East Asian languages
3466:        'zh': ['', '', '', '', ''],
3467:        'ja': ['', '', '', '', ''],
3468:        'ko': ['', '', '', '', '']
3469:    };
3470:    
3471:    // Default pattern for languages not in our map
3472:    const defaultPattern = ['Lorem', 'Ipsum', 'Dolor', 'Sit', 'Amet'];
3473:    
3474:    // Get the pattern for the selected language or use default
3475:    const pattern = langPatterns[language] || defaultPattern;
3476:    
3477:    // Create a "translated" version by replacing some words and keeping structure
3478:    const words = text.split(/\s+/);
3479:    let translatedText = '';
3480:    
3481:    for (let i = 0; i < words.length; i++) {
3482:        if (i % 5 === 0 && i < words.length) {
3483:            translatedText += pattern[i % pattern.length] + ' ';
3484:        } else if (i % 7 === 0) {
3485:            translatedText += pattern[(i+1) % pattern.length] + ' ';
3486:        } else {
3487:            // Keep some words as-is to simulate partial translation
3488:            translatedText += words[i] + ' ';
3489:        }
3490:        
3491:        // Add line breaks to maintain readability
3492:        if (i % 15 === 14) {
3493:            translatedText += '<br>';
3494:        }
3495:    }
3496:    
3497:    return translatedText;
3498:}
